{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/amantimalsina/Mamba-SAE/blob/main/training_a_sparse_autoencoder_for_mamba.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5O8tQblzOVHu"
      },
      "source": [
        "# A very basic SAE Training Tutorial\n",
        "\n",
        "Please note that it is very easy for tutorial code to go stale so please have a low bar for raising an issue in the"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "shAFb9-lOVHu"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install sae-lens transformer-lens circuitsvis\n",
        "\n",
        "# MambaLens:\n",
        "!pip install git+https://github.com/Phylliida/MambaLens.git\n",
        "# For faster inference in SSMs:\n",
        "!pip install causal_conv1d mamba-ssm"
      ],
      "metadata": {
        "collapsed": true,
        "id": "9L-LZJFkmxNt",
        "outputId": "936438b4-3403-4590-fcab-f78172b8ebb8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sae-lens in /usr/local/lib/python3.10/dist-packages (3.18.2)\n",
            "Requirement already satisfied: transformer-lens in /usr/local/lib/python3.10/dist-packages (2.4.0)\n",
            "Requirement already satisfied: circuitsvis in /usr/local/lib/python3.10/dist-packages (1.43.2)\n",
            "Requirement already satisfied: automated-interpretability<1.0.0,>=0.0.5 in /usr/local/lib/python3.10/dist-packages (from sae-lens) (0.0.6)\n",
            "Requirement already satisfied: babe<0.0.8,>=0.0.7 in /usr/local/lib/python3.10/dist-packages (from sae-lens) (0.0.7)\n",
            "Requirement already satisfied: datasets<3.0.0,>=2.17.1 in /usr/local/lib/python3.10/dist-packages (from sae-lens) (2.21.0)\n",
            "Requirement already satisfied: matplotlib<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from sae-lens) (3.9.2)\n",
            "Requirement already satisfied: matplotlib-inline<0.2.0,>=0.1.6 in /usr/local/lib/python3.10/dist-packages (from sae-lens) (0.1.7)\n",
            "Requirement already satisfied: nltk<4.0.0,>=3.8.1 in /usr/local/lib/python3.10/dist-packages (from sae-lens) (3.8.1)\n",
            "Requirement already satisfied: plotly<6.0.0,>=5.19.0 in /usr/local/lib/python3.10/dist-packages (from sae-lens) (5.24.0)\n",
            "Requirement already satisfied: plotly-express<0.5.0,>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from sae-lens) (0.4.1)\n",
            "Requirement already satisfied: pytest-profiling<2.0.0,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from sae-lens) (1.7.0)\n",
            "Requirement already satisfied: python-dotenv<2.0.0,>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from sae-lens) (1.0.1)\n",
            "Requirement already satisfied: pyyaml<7.0.0,>=6.0.1 in /usr/local/lib/python3.10/dist-packages (from sae-lens) (6.0.1)\n",
            "Requirement already satisfied: pyzmq==26.0.0 in /usr/local/lib/python3.10/dist-packages (from sae-lens) (26.0.0)\n",
            "Requirement already satisfied: safetensors<0.5.0,>=0.4.2 in /usr/local/lib/python3.10/dist-packages (from sae-lens) (0.4.3)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.38.1 in /usr/local/lib/python3.10/dist-packages (from sae-lens) (4.41.2)\n",
            "Requirement already satisfied: typer<0.13.0,>=0.12.3 in /usr/local/lib/python3.10/dist-packages (from sae-lens) (0.12.3)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.10.0 in /usr/local/lib/python3.10/dist-packages (from sae-lens) (4.12.2)\n",
            "Requirement already satisfied: zstandard<0.23.0,>=0.22.0 in /usr/local/lib/python3.10/dist-packages (from sae-lens) (0.22.0)\n",
            "Requirement already satisfied: accelerate>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from transformer-lens) (0.33.0)\n",
            "Requirement already satisfied: beartype<0.15.0,>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from transformer-lens) (0.14.1)\n",
            "Requirement already satisfied: better-abc<0.0.4,>=0.0.3 in /usr/local/lib/python3.10/dist-packages (from transformer-lens) (0.0.3)\n",
            "Requirement already satisfied: einops>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from transformer-lens) (0.8.0)\n",
            "Requirement already satisfied: fancy-einsum>=0.0.3 in /usr/local/lib/python3.10/dist-packages (from transformer-lens) (0.0.3)\n",
            "Requirement already satisfied: jaxtyping>=0.2.11 in /usr/local/lib/python3.10/dist-packages (from transformer-lens) (0.2.33)\n",
            "Requirement already satisfied: numpy>=1.24 in /usr/local/lib/python3.10/dist-packages (from transformer-lens) (1.25.2)\n",
            "Requirement already satisfied: pandas>=1.1.5 in /usr/local/lib/python3.10/dist-packages (from transformer-lens) (2.0.3)\n",
            "Requirement already satisfied: rich>=12.6.0 in /usr/local/lib/python3.10/dist-packages (from transformer-lens) (13.7.1)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from transformer-lens) (0.1.99)\n",
            "Requirement already satisfied: torch>=1.10 in /usr/local/lib/python3.10/dist-packages (from transformer-lens) (2.1.2)\n",
            "Requirement already satisfied: tqdm>=4.64.1 in /usr/local/lib/python3.10/dist-packages (from transformer-lens) (4.66.4)\n",
            "Requirement already satisfied: wandb>=0.13.5 in /usr/local/lib/python3.10/dist-packages (from transformer-lens) (0.17.8)\n",
            "Requirement already satisfied: importlib-metadata>=5.1.0 in /usr/local/lib/python3.10/dist-packages (from circuitsvis) (8.0.0)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from circuitsvis) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from circuitsvis) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from circuitsvis) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from circuitsvis) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from circuitsvis) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from circuitsvis) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from circuitsvis) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from circuitsvis) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from circuitsvis) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in /usr/local/lib/python3.10/dist-packages (from circuitsvis) (2.18.1)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from circuitsvis) (12.1.105)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from circuitsvis) (2.1.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->circuitsvis) (12.6.68)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from triton==2.1.0->circuitsvis) (3.15.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.23.0->transformer-lens) (24.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.23.0->transformer-lens) (5.9.5)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.23.0->transformer-lens) (0.23.4)\n",
            "Requirement already satisfied: blobfile<3.0.0,>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from automated-interpretability<1.0.0,>=0.0.5->sae-lens) (2.1.1)\n",
            "Requirement already satisfied: boostedblob<0.16.0,>=0.15.3 in /usr/local/lib/python3.10/dist-packages (from automated-interpretability<1.0.0,>=0.0.5->sae-lens) (0.15.4)\n",
            "Requirement already satisfied: httpx<0.28.0,>=0.27.0 in /usr/local/lib/python3.10/dist-packages (from automated-interpretability<1.0.0,>=0.0.5->sae-lens) (0.27.2)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.10.1 in /usr/local/lib/python3.10/dist-packages (from automated-interpretability<1.0.0,>=0.0.5->sae-lens) (3.10.7)\n",
            "Requirement already satisfied: scikit-learn<2.0.0,>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from automated-interpretability<1.0.0,>=0.0.5->sae-lens) (1.2.2)\n",
            "Requirement already satisfied: tiktoken<0.7.0,>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from automated-interpretability<1.0.0,>=0.0.5->sae-lens) (0.6.0)\n",
            "Requirement already satisfied: py2store in /usr/local/lib/python3.10/dist-packages (from babe<0.0.8,>=0.0.7->sae-lens) (0.1.20)\n",
            "Requirement already satisfied: graze in /usr/local/lib/python3.10/dist-packages (from babe<0.0.8,>=0.0.7->sae-lens) (0.1.24)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets<3.0.0,>=2.17.1->sae-lens) (17.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets<3.0.0,>=2.17.1->sae-lens) (0.3.8)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets<3.0.0,>=2.17.1->sae-lens) (2.32.3)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets<3.0.0,>=2.17.1->sae-lens) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets<3.0.0,>=2.17.1->sae-lens) (0.70.16)\n",
            "Requirement already satisfied: fsspec[http]<=2024.6.1,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets<3.0.0,>=2.17.1->sae-lens) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets<3.0.0,>=2.17.1->sae-lens) (3.9.5)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata>=5.1.0->circuitsvis) (3.19.2)\n",
            "Requirement already satisfied: typeguard==2.13.3 in /usr/local/lib/python3.10/dist-packages (from jaxtyping>=0.2.11->transformer-lens) (2.13.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4.0.0,>=3.8.3->sae-lens) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4.0.0,>=3.8.3->sae-lens) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4.0.0,>=3.8.3->sae-lens) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4.0.0,>=3.8.3->sae-lens) (1.4.5)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4.0.0,>=3.8.3->sae-lens) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4.0.0,>=3.8.3->sae-lens) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4.0.0,>=3.8.3->sae-lens) (2.8.2)\n",
            "Requirement already satisfied: traitlets in /usr/local/lib/python3.10/dist-packages (from matplotlib-inline<0.2.0,>=0.1.6->sae-lens) (5.7.1)\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 3108, in _dep_map\n",
            "    return self.__dep_map\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 2901, in __getattr__\n",
            "    raise AttributeError(attr)\n",
            "AttributeError: _DistInfoDistribution__dep_map\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/base_command.py\", line 169, in exc_logging_wrapper\n",
            "    status = run_func(*args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/req_command.py\", line 242, in wrapper\n",
            "    return func(self, options, args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/commands/install.py\", line 377, in run\n",
            "    requirement_set = resolver.resolve(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/resolution/resolvelib/resolver.py\", line 92, in resolve\n",
            "    result = self._result = resolver.resolve(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/resolvelib/resolvers.py\", line 546, in resolve\n",
            "    state = resolution.resolve(requirements, max_rounds=max_rounds)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/resolvelib/resolvers.py\", line 427, in resolve\n",
            "    failure_causes = self._attempt_to_pin_criterion(name)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/resolvelib/resolvers.py\", line 239, in _attempt_to_pin_criterion\n",
            "    criteria = self._get_updated_criteria(candidate)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/resolvelib/resolvers.py\", line 229, in _get_updated_criteria\n",
            "    for requirement in self._p.get_dependencies(candidate=candidate):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/resolution/resolvelib/provider.py\", line 244, in get_dependencies\n",
            "    return [r for r in candidate.iter_dependencies(with_requires) if r is not None]\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/resolution/resolvelib/provider.py\", line 244, in <listcomp>\n",
            "    return [r for r in candidate.iter_dependencies(with_requires) if r is not None]\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/resolution/resolvelib/candidates.py\", line 391, in iter_dependencies\n",
            "    for r in self.dist.iter_dependencies():\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/metadata/pkg_resources.py\", line 216, in iter_dependencies\n",
            "    return self._dist.requires(extras)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 2821, in requires\n",
            "    dm = self._dep_map\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 3110, in _dep_map\n",
            "    self.__dep_map = self._compute_dependencies()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 3132, in _compute_dependencies\n",
            "    dm[s_extra] = [r for r in reqs_for_extra(extra) if r not in common]\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 3132, in <listcomp>\n",
            "    dm[s_extra] = [r for r in reqs_for_extra(extra) if r not in common]\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 3124, in reqs_for_extra\n",
            "    if not req.marker or req.marker.evaluate({'extra': extra}):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/packaging/markers.py\", line 304, in evaluate\n",
            "    return _evaluate_markers(self._markers, current_environment)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/packaging/markers.py\", line 226, in _evaluate_markers\n",
            "    assert isinstance(marker, (list, tuple, str))\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/pip3\", line 8, in <module>\n",
            "    sys.exit(main())\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/main.py\", line 79, in main\n",
            "    return command.main(cmd_args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/base_command.py\", line 101, in main\n",
            "    return self._main(args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/base_command.py\", line 223, in _main\n",
            "    return run(options, args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/base_command.py\", line 206, in exc_logging_wrapper\n",
            "    logger.critical(\"Operation cancelled by user\")\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1524, in critical\n",
            "    self._log(CRITICAL, msg, args, **kwargs)\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1624, in _log\n",
            "    self.handle(record)\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1634, in handle\n",
            "    self.callHandlers(record)\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1696, in callHandlers\n",
            "    hdlr.handle(record)\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 968, in handle\n",
            "    self.emit(record)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/utils/logging.py\", line 168, in emit\n",
            "    message = self.format(record)\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 943, in format\n",
            "    return fmt.format(record)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/utils/logging.py\", line 112, in format\n",
            "    formatted = super().format(record)\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 679, in format\n",
            "    if self.usesTime():\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 647, in usesTime\n",
            "    return self._style.usesTime()\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 424, in usesTime\n",
            "    return self._fmt.find(self.asctime_search) >= 0\n",
            "KeyboardInterrupt\n",
            "^C\n",
            "Collecting git+https://github.com/Phylliida/MambaLens.git\n",
            "  Cloning https://github.com/Phylliida/MambaLens.git to /tmp/pip-req-build-45dhg7ce\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/Phylliida/MambaLens.git /tmp/pip-req-build-45dhg7ce\n",
            "\u001b[31m  ERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
            "\u001b[0mRequirement already satisfied: causal_conv1d in /usr/local/lib/python3.10/dist-packages (1.4.0)\n",
            "Requirement already satisfied: mamba-ssm in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from causal_conv1d) (2.1.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from causal_conv1d) (24.1)\n",
            "Requirement already satisfied: ninja in /usr/local/lib/python3.10/dist-packages (from causal_conv1d) (1.11.1.1)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (from mamba-ssm) (0.8.0)\n",
            "Requirement already satisfied: triton in /usr/local/lib/python3.10/dist-packages (from mamba-ssm) (2.1.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from mamba-ssm) (4.41.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->causal_conv1d) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->causal_conv1d) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->causal_conv1d) (1.13.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->causal_conv1d) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->causal_conv1d) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->causal_conv1d) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->causal_conv1d) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->causal_conv1d) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->causal_conv1d) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch->causal_conv1d) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch->causal_conv1d) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch->causal_conv1d) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch->causal_conv1d) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch->causal_conv1d) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch->causal_conv1d) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in /usr/local/lib/python3.10/dist-packages (from torch->causal_conv1d) (2.18.1)\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/base_command.py\", line 169, in exc_logging_wrapper\n",
            "    status = run_func(*args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/req_command.py\", line 242, in wrapper\n",
            "    return func(self, options, args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/commands/install.py\", line 377, in run\n",
            "    requirement_set = resolver.resolve(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/resolution/resolvelib/resolver.py\", line 92, in resolve\n",
            "    result = self._result = resolver.resolve(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/resolvelib/resolvers.py\", line 546, in resolve\n",
            "    state = resolution.resolve(requirements, max_rounds=max_rounds)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/resolvelib/resolvers.py\", line 427, in resolve\n",
            "    failure_causes = self._attempt_to_pin_criterion(name)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/resolvelib/resolvers.py\", line 239, in _attempt_to_pin_criterion\n",
            "    criteria = self._get_updated_criteria(candidate)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/resolvelib/resolvers.py\", line 230, in _get_updated_criteria\n",
            "    self._add_to_criteria(criteria, requirement, parent=candidate)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/resolvelib/resolvers.py\", line 148, in _add_to_criteria\n",
            "    matches = self._p.find_matches(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/resolution/resolvelib/provider.py\", line 231, in find_matches\n",
            "    return self._factory.find_candidates(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/resolution/resolvelib/factory.py\", line 391, in find_candidates\n",
            "    parsed_requirement = get_requirement(identifier)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/utils/packaging.py\", line 45, in get_requirement\n",
            "    return Requirement(req_string)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/packaging/requirements.py\", line 102, in __init__\n",
            "    req = REQUIREMENT.parseString(requirement_string)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 1131, in parse_string\n",
            "    loc, tokens = self._parse(instring, 0)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 817, in _parseNoCache\n",
            "    loc, tokens = self.parseImpl(instring, pre_loc, doActions)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 3886, in parseImpl\n",
            "    loc, exprtokens = e._parse(instring, loc, doActions)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 817, in _parseNoCache\n",
            "    loc, tokens = self.parseImpl(instring, pre_loc, doActions)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 4114, in parseImpl\n",
            "    return e._parse(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 817, in _parseNoCache\n",
            "    loc, tokens = self.parseImpl(instring, pre_loc, doActions)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 3864, in parseImpl\n",
            "    loc, resultlist = self.exprs[0]._parse(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 817, in _parseNoCache\n",
            "    loc, tokens = self.parseImpl(instring, pre_loc, doActions)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 3886, in parseImpl\n",
            "    loc, exprtokens = e._parse(instring, loc, doActions)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 817, in _parseNoCache\n",
            "    loc, tokens = self.parseImpl(instring, pre_loc, doActions)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 4959, in parseImpl\n",
            "    loc, tokens = self_expr._parse(instring, loc, doActions, callPreParse=False)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 817, in _parseNoCache\n",
            "    loc, tokens = self.parseImpl(instring, pre_loc, doActions)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 4108, in parseImpl\n",
            "    def parseImpl(self, instring, loc, doActions=True):\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/pip3\", line 8, in <module>\n",
            "    sys.exit(main())\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/main.py\", line 79, in main\n",
            "    return command.main(cmd_args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/base_command.py\", line 101, in main\n",
            "    return self._main(args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/base_command.py\", line 223, in _main\n",
            "    return run(options, args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/base_command.py\", line 206, in exc_logging_wrapper\n",
            "    logger.critical(\"Operation cancelled by user\")\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1524, in critical\n",
            "    self._log(CRITICAL, msg, args, **kwargs)\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1624, in _log\n",
            "    self.handle(record)\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1634, in handle\n",
            "    self.callHandlers(record)\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1696, in callHandlers\n",
            "    hdlr.handle(record)\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 968, in handle\n",
            "    self.emit(record)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/utils/logging.py\", line 172, in emit\n",
            "    style = Style(color=\"red\")\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/rich/style.py\", line 122, in __init__\n",
            "    def __init__(\n",
            "KeyboardInterrupt\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# %%\n",
        "import os\n",
        "import json\n",
        "import random\n",
        "from pathlib import Path\n",
        "import gc\n",
        "# %%\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import einops\n",
        "# %%\n",
        "import wandb\n",
        "from tqdm import tqdm\n",
        "import pprint\n",
        "# %%\n",
        "import argparse\n",
        "# %%\n",
        "from transformers import AutoTokenizer\n",
        "import datasets\n",
        "from datasets import load_dataset\n",
        "# %%\n",
        "from transformer_lens.utils import test_prompt\n",
        "import circuitsvis as cv  # optional dep, install with pip install circuitsvis\n",
        "from functools import partial\n",
        "# %%\n",
        "import mamba_lens"
      ],
      "metadata": {
        "id": "mHOdhs_lnCGg"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uy-b3CcSOVHu",
        "outputId": "ff442bc3-3c29-4f03-9992-5dd67ad9ce5a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "if torch.cuda.is_available():\n",
        "    device = \"cuda\"\n",
        "elif torch.backends.mps.is_available():\n",
        "    device = \"mps\"\n",
        "else:\n",
        "    device = \"cpu\"\n",
        "\n",
        "print(\"Using device:\", device)\n",
        "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oe2nlqf-OVHv"
      },
      "source": [
        "# Model Selection and Evaluation (Feel Free to Skip)\n",
        "\n",
        "We'll use the runner to train an SAE on a TinyStories Model. This is a very small model so we can train an SAE on it quite quickly. Before we get started, let's load in the model with `transformer_lens` and see what it can do.\n",
        "\n",
        "TransformerLens gives us 2 functions that are useful here (and circuits viz provides a third):\n",
        "1. `transformer_lens.utils.test_prompt` will help us see when the model can infer one token.\n",
        "2. `HookedTransformer.generate` will help us see what happens when we sample from the model.\n",
        "3. `circuitsvis.logits.token_log_probs` will help us visualize the log probs of tokens at several positions in a prompt."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = mamba_lens.HookedMamba.from_pretrained(\n",
        "                              \"state-spaces/mamba-130m\",\n",
        "                              device='cuda'\n",
        "                              )\n",
        "tokenizer = AutoTokenizer.from_pretrained('EleutherAI/gpt-neox-20b')"
      ],
      "metadata": {
        "id": "OO0grtwgzyTi",
        "outputId": "4baeb65b-cf57-4767-afe9-e21ba2746974",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  return self.fget.__get__(instance, owner)()\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Moving model to device:  cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "n_layers = model.cfg.n_layers\n",
        "d_model = model.cfg.d_model\n",
        "d_state = model.cfg.d_state\n",
        "d_conv = model.cfg.d_conv\n",
        "n_ctx = model.cfg.n_ctx\n",
        "d_inner = model.cfg.d_inner\n",
        "print(f\"n_layers: {n_layers}\")\n",
        "print(f\"d_model: {d_model}\")\n",
        "print(f\"d_state: {d_state}\")\n",
        "print(f\"d_conv: {d_conv}\")\n",
        "print(f\"n_ctx: {n_ctx}\")\n",
        "print(f\"d_inner: {d_inner}\")\n",
        "print(model.cfg)"
      ],
      "metadata": {
        "id": "ZqmAhJ71RtYl",
        "outputId": "5dba2a7c-a4e6-4cf8-9148-190cda8d1eca",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "n_layers: 24\n",
            "d_model: 768\n",
            "d_state: 16\n",
            "d_conv: 4\n",
            "n_ctx: 2048\n",
            "d_inner: 1536\n",
            "MambaCfg(d_model=768, n_layers=24, vocab_size=50280, d_state=16, expand=2, dt_rank=48, d_conv=4, pad_vocab_size_multiple=8, conv_bias=True, bias=False, default_prepend_bos=True, tokenizer_prepends_bos=False, n_ctx=2048, device='cuda', initializer_cfg=MambaInitCfg(initializer_range=(0.02,), rescale_prenorm_residual=(True,), n_residuals_per_layer=(1,), dt_init=('random',), dt_scale=(1.0,), dt_min=(0.001,), dt_max=(0.1,), dt_init_floor=0.0001), d_inner=1536)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NIWDRTgp_V6z",
        "outputId": "2743ff15-16dd-409d-8a68-e3e7ef60e833"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HookedMamba(\n",
            "  (embedding): Embedding(50280, 768)\n",
            "  (hook_embed): HookPoint()\n",
            "  (blocks): ModuleList(\n",
            "    (0-23): 24 x HookedMambaBlock(\n",
            "      (hook_resid_pre): HookPoint()\n",
            "      (hook_layer_input): HookPoint()\n",
            "      (norm): RMSNorm()\n",
            "      (hook_normalized_input): HookPoint()\n",
            "      (skip_proj): Linear(in_features=768, out_features=1536, bias=False)\n",
            "      (hook_skip): HookPoint()\n",
            "      (in_proj): Linear(in_features=768, out_features=1536, bias=False)\n",
            "      (hook_in_proj): HookPoint()\n",
            "      (conv1d): Conv1d(1536, 1536, kernel_size=(4,), stride=(1,), padding=(3,), groups=1536)\n",
            "      (hook_conv): HookPoint()\n",
            "      (hook_ssm_input): HookPoint()\n",
            "      (W_delta_1): Linear(in_features=1536, out_features=48, bias=False)\n",
            "      (W_delta_2): Linear(in_features=48, out_features=1536, bias=True)\n",
            "      (W_B): Linear(in_features=1536, out_features=16, bias=False)\n",
            "      (W_C): Linear(in_features=1536, out_features=16, bias=False)\n",
            "      (hook_h_start): HookPoint()\n",
            "      (hook_delta_1): HookPoint()\n",
            "      (hook_delta_2): HookPoint()\n",
            "      (hook_delta): HookPoint()\n",
            "      (hook_A): HookPoint()\n",
            "      (hook_A_bar): HookPoint()\n",
            "      (hook_B): HookPoint()\n",
            "      (hook_B_bar): HookPoint()\n",
            "      (hook_C): HookPoint()\n",
            "      (hook_h): InputDependentHookPoint()\n",
            "      (hook_y): HookPoint()\n",
            "      (hook_ssm_output): HookPoint()\n",
            "      (hook_after_skip): HookPoint()\n",
            "      (out_proj): Linear(in_features=1536, out_features=768, bias=False)\n",
            "      (hook_out_proj): HookPoint()\n",
            "      (hook_resid_post): HookPoint()\n",
            "    )\n",
            "  )\n",
            "  (norm): RMSNorm()\n",
            "  (hook_norm): HookPoint()\n",
            "  (lm_head): Linear(in_features=768, out_features=50280, bias=False)\n",
            "  (hook_logits): HookPoint()\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZZfKT5aDOVHv"
      },
      "source": [
        "Let's start by generating some stories using the model."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "TPXH2kSu3wSV"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Feed it back to the model and keep predicting tokens:\n",
        "prompt = \"Once upon a time, there was a little girl named Lily. She lived in a big, happy little girl. On her big adventure,\"\n",
        "for i in range(2):\n",
        "    tokens = tokenizer(prompt, return_tensors=\"pt\").input_ids.to(device)\n",
        "    logits, activations = model.run_with_cache(tokens,\n",
        "                                               fast_ssm=True,\n",
        "                                               fast_conv=True,\n",
        "                                               warn_disabled_hooks=False\n",
        "                                               )\n",
        "    generated_text = tokenizer.batch_decode(logits.argmax(dim=-1)[0])\n",
        "    prompt += ' '.join(generated_text)\n",
        "print(prompt)"
      ],
      "metadata": {
        "id": "WdKGGuWV1Ekh",
        "outputId": "81adbb41-2a62-4960-e87d-a80acd80a829",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Once upon a time, there was a little girl named Lily. She lived in a big, happy little girl. On her big adventure, again  a  time ,  there  was  a  man  girl  named  Alice  who  She  was  in  a  small  house  big  house  house 's  She  the  little , ,  she again  a  time ,  there  was  a  man  girl  named  Alice  who  She  was  in  a  small  house  big  house  house 's  She  the  little , ,  she , \n",
            "  little little ,  she she  was was  a a  little little  named who    named    L ice . who    was    was    a    a    big    girl    in    girl    in    s    big    was    little          little   \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KsfJX-YpOVHv"
      },
      "source": [
        "### Spot checking model abilities with `transformer_lens.utils.test_prompt`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "TpmPoj7uOVHv",
        "outputId": "f74070df-3e64-411d-bad8-2f2bdf0688d3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenized prompt: ['<|endoftext|>', 'Once', ' upon', ' a', ' time', ',', ' there', ' was', ' a', ' little', ' girl', ' named', ' Lily', '.', ' She', ' lived', ' in', ' a', ' big', ',', ' happy', ' little', ' girl', '.', ' On', ' her', ' big', ' adventure', ',']\n",
            "Tokenized answer: [' Lily']\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Performance on answer token:\n",
              "\u001b[1mRank: \u001b[0m\u001b[1;36m1\u001b[0m\u001b[1m        Logit: \u001b[0m\u001b[1;36m24.37\u001b[0m\u001b[1m Prob: \u001b[0m\u001b[1;36m12.73\u001b[0m\u001b[1m% Token: | Lily|\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Performance on answer token:\n",
              "<span style=\"font-weight: bold\">Rank: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">        Logit: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">24.37</span><span style=\"font-weight: bold\"> Prob: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12.73</span><span style=\"font-weight: bold\">% Token: | Lily|</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 0th token. Logit: 25.97 Prob: 63.23% Token: | she|\n",
            "Top 1th token. Logit: 24.37 Prob: 12.73% Token: | Lily|\n",
            "Top 2th token. Logit: 23.73 Prob:  6.74% Token: | the|\n",
            "Top 3th token. Logit: 23.00 Prob:  3.25% Token: | her|\n",
            "Top 4th token. Logit: 21.95 Prob:  1.14% Token: | a|\n",
            "Top 5th token. Logit: 21.90 Prob:  1.08% Token: | there|\n",
            "Top 6th token. Logit: 21.52 Prob:  0.74% Token: | they|\n",
            "Top 7th token. Logit: 21.24 Prob:  0.56% Token: | it|\n",
            "Top 8th token. Logit: 20.74 Prob:  0.34% Token: | he|\n",
            "Top 9th token. Logit: 20.61 Prob:  0.30% Token: | all|\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mRanks of the answer tokens:\u001b[0m \u001b[1m[\u001b[0m\u001b[1m(\u001b[0m\u001b[32m' Lily'\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Ranks of the answer tokens:</span> <span style=\"font-weight: bold\">[(</span><span style=\"color: #008000; text-decoration-color: #008000\">' Lily'</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">)]</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Test the model with a prompt\n",
        "test_prompt(\n",
        "    \"Once upon a time, there was a little girl named Lily. She lived in a big, happy little girl. On her big adventure,\",\n",
        "    \" Lily\",\n",
        "    model,\n",
        "    prepend_space_to_answer=False,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jGzOvReDOVHv"
      },
      "source": [
        "In the output above, we see that the model assigns ~ 70% probability to \"she\" being the next token, and a 13% chance to \" Lily\" being the next token. Other names like Lucy or Anna are not highly ranked."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QH8YOZOzOVHv"
      },
      "source": [
        "### Exploring Model Capabilities with Log Probs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "50mqTBihOVHw"
      },
      "source": [
        "Looking at token ranking for a single prompt is interesting, but a much higher through way to understand models is to look at token log probs for all tokens in text. We can use the `circuits_vis` package to get a nice visualization where we can see tokenization, and hover to get the top5 tokens by log probability. Darker tokens are tokens where the model assigned a higher probability to the actual next token."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Tic0RCUpOVHw",
        "outputId": "7d1f8a0e-3a03-447b-d9a7-821a1feb3ecc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 420
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<circuitsvis.utils.render.RenderedHTML at 0x786051d92c50>"
            ],
            "text/html": [
              "<div id=\"circuits-vis-04f5c857-62a8\" style=\"margin: 15px 0;\"/>\n",
              "    <script crossorigin type=\"module\">\n",
              "    import { render, TokenLogProbs } from \"https://unpkg.com/circuitsvis@1.43.2/dist/cdn/esm.js\";\n",
              "    render(\n",
              "      \"circuits-vis-04f5c857-62a8\",\n",
              "      TokenLogProbs,\n",
              "      {\"prompt\": [\"<|endoftext|>\", \"Hi\", \",\", \" how\", \" are\", \" you\", \" doing\", \" this\", \"?\", \" I\", \"'m\", \" really\", \" enjoying\", \" your\", \" posts\"], \"topKLogProbs\": [[-2.0294628143310547, -3.0690135955810547, -3.8244991302490234, -3.989736557006836, -4.26222038269043, -4.317106246948242, -4.328229904174805, -4.485235214233398, -4.554662704467773, -4.594663619995117], [-1.3927068710327148, -2.5150022506713867, -2.5160322189331055, -2.6099462509155273, -3.24735164642334, -3.2618398666381836, -3.554629325866699, -4.013983726501465, -4.080687522888184, -4.314108848571777], [-1.303799033164978, -1.4873889684677124, -3.50083589553833, -3.786411762237549, -3.9487576484680176, -4.133190631866455, -4.218555927276611, -4.295185565948486, -4.302296161651611, -4.901237964630127], [-0.6492132544517517, -2.6000266075134277, -2.6452231407165527, -2.8917746543884277, -3.3241782188415527, -3.5083975791931152, -3.8196158409118652, -4.136167049407959, -4.278619289398193, -4.584020137786865], [-0.14413581788539886, -3.399113893508911, -3.9703457355499268, -4.102113246917725, -4.324212551116943, -4.549630641937256, -5.142259120941162, -5.242311000823975, -5.377862453460693, -5.931859493255615], [-0.49467137455940247, -2.9921326637268066, -3.292328357696533, -3.5465798377990723, -3.6361184120178223, -3.727295398712158, -3.734976291656494, -3.8597970008850098, -4.2194085121154785, -4.3274922370910645], [-0.5796945691108704, -2.707700490951538, -2.898732900619507, -3.0418717861175537, -3.262746572494507, -3.9314591884613037, -4.104043960571289, -4.155637741088867, -4.71589469909668, -4.839509963989258], [-1.8530129194259644, -1.9254463911056519, -2.492478370666504, -2.714287757873535, -3.0006532669067383, -3.189457893371582, -3.54665470123291, -3.559250831604004, -3.8983240127563477, -4.161248207092285], [-1.49098801612854, -1.741995096206665, -3.386972665786743, -3.696485757827759, -4.069925308227539, -4.228109359741211, -4.241235733032227, -4.310155868530273, -4.394315719604492, -4.482927322387695], [-2.0374717712402344, -2.0487632751464844, -2.1472549438476562, -3.1236801147460938, -3.2557640075683594, -3.368824005126953, -3.699481964111328, -3.827117919921875, -3.9906387329101562, -4.044624328613281], [-2.7568933963775635, -3.3331987857818604, -3.366722345352173, -3.4078867435455322, -3.4121363162994385, -3.7332193851470947, -3.7455294132232666, -3.8044817447662354, -3.8317339420318604, -3.8841631412506104], [-1.9323383569717407, -2.273963451385498, -2.542534351348877, -2.7996325492858887, -3.1195874214172363, -3.2023062705993652, -3.319897174835205, -3.3871636390686035, -3.731433391571045, -4.039961338043213], [-1.674013376235962, -1.9695265293121338, -2.320780038833618, -2.3385069370269775, -3.2167418003082275, -3.638895273208618, -3.7556326389312744, -3.9974348545074463, -4.186563491821289, -4.362428665161133], [-2.3473637104034424, -2.7963955402374268, -3.28851056098938, -3.288884401321411, -3.5008060932159424, -4.3729143142700195, -4.476365089416504, -4.516667366027832, -4.5658769607543945, -4.670201301574707]], \"topKTokens\": [[\"Q\", \"The\", \"1\", \"A\", \"\\n\", \"In\", \"[\", \"This\", \"---\", \"/*\"], [\",\", \" everyone\", \" guys\", \" there\", \" all\", \"!\", \".\", \" everybody\", \" I\", \" and\"], [\" I\", \"\\n\", \" my\", \" i\", \" this\", \"I\", \" how\", \"\\n\\n\\n\", \" everyone\", \" My\"], [\" are\", \" can\", \" is\", \"'s\", \" do\", \" you\", \"\\u2019\", \"s\", \" may\", \"'re\"], [\" you\", \" ya\", \" u\", \" things\", \" y\", \" the\", \" your\", \" all\", \" people\", \" ye\"], [\"?\", \"!\", \" doing\", \" guys\", \",\", \" and\", \"\\n\", \".\", \" today\", \" ?\"], [\"?\", \"!\", \",\", \".\", \" today\", \" ?\", \"\\n\", \" and\", \"??\", \"?!\"], [\" morning\", \" week\", \" time\", \" weekend\", \" is\", \" year\", \"?\", \" month\", \" afternoon\", \" evening\"], [\"\\n\", \" I\", \"  \", \" It\", \" My\", \" What\", \" We\", \" You\", \" How\", \" Do\"], [\" have\", \"'m\", \" am\", \"'ve\", \" was\", \" just\", \" love\", \" need\", \" can\", \"\\u2019\"], [\" a\", \" so\", \" looking\", \" not\", \" in\", \" going\", \" having\", \" trying\", \" new\", \" just\"], [\" looking\", \" excited\", \" happy\", \" enjoying\", \" glad\", \" sorry\", \" interested\", \" impressed\", \" new\", \" curious\"], [\" the\", \" this\", \" my\", \" your\", \" it\", \" playing\", \" reading\", \" working\", \" watching\", \" all\"], [\" blog\", \" site\", \" work\", \" website\", \" new\", \" posts\", \" book\", \" post\", \" product\", \" videos\"]], \"correctTokenRank\": [172, 0, 6, 0, 0, 2, 10, 6, 1, 1, 18, 3, 3, 5], \"correctTokenLogProb\": [-7.331357955932617, -1.3927068710327148, -4.218555927276611, -0.6492132544517517, -0.14413581788539886, -3.292328357696533, -5.031167984008789, -3.54665470123291, -1.741995096206665, -2.0487632751464844, -4.5759735107421875, -2.7996325492858887, -2.3385069370269775, -4.3729143142700195]}\n",
              "    )\n",
              "    </script>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "# Let's make a longer prompt and see the log probabilities of the tokens\n",
        "example_prompt = \"\"\"Hi, how are you doing this? I'm really enjoying your posts\"\"\"\n",
        "logits, cache = model.run_with_cache(example_prompt)\n",
        "cv.logits.token_log_probs(\n",
        "    model.to_tokens(example_prompt),\n",
        "    model(example_prompt)[0].log_softmax(dim=-1),\n",
        "    model.to_string,\n",
        ")\n",
        "# hover on the output to see the result."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "# Code used to remove the \"rare freq direction\", the shared direction among the ultra low frequency features.\n",
        "# I experimented with removing it and retraining the autoencoder.\n",
        "if cfg[\"remove_rare_dir\"]:\n",
        "    rare_freq_dir = torch.load(\"rare_freq_dir.pt\")\n",
        "    rare_freq_dir.requires_grad = False\n",
        "\n",
        "# %%\n",
        "\"\"\"\n",
        "# Training cfg:\n",
        "cfg = {\n",
        "    # Data parameters\n",
        "    \"num_tokens\": int(4e4),  # Total number of tokens to use\n",
        "    \"batch_size\": 32,  # Batch size for training\n",
        "\n",
        "    # Model parameters\n",
        "    \"act_name\": \"hook_norm\",  # Name of the activation to extract\n",
        "    \"dict_size\": 1536,\n",
        "    \"l1_coeff\": 3e-4,\n",
        "    \"beta1\": 0.9,\n",
        "    \"beta2\": 0.99,\n",
        "    \"dict_mult\": 32,\n",
        "    \"seq_len\": 128,\n",
        "    \"remove_rare_dir\": False,\n",
        "    \"device\": \"cuda:0\",\n",
        "    \"enc_dtype\": \"fp32\",\n",
        "    \"seed\": 16,\n",
        "    \"act_size\": 768,\n",
        "    \"model_batch_size\": 32,\n",
        "\n",
        "    # Training parameters\n",
        "    \"num_epochs\": 10,  # Number of epochs to train\n",
        "    \"lr\": 1e-3,  # Learning rate\n",
        "    \"beta1\": 0.9,  # Adam optimizer beta1\n",
        "    \"beta2\": 0.999,  # Adam optimizer beta2\n",
        "\n",
        "    # Regularization\n",
        "    \"l1_weight\": 1e-5,  # L1 regularization weight\n",
        "    \"l2_weight\": 1e-5,  # L2 regularization weight\n",
        "\n",
        "    # Logging and checkpointing\n",
        "    \"log_every\": 100,  # Log every N batches\n",
        "    \"eval_every\": 100,  # Evaluate reconstruction every N batches\n",
        "    \"recons_every\": 500,  # Reconstruct every N batches\n",
        "    \"save_every\": 500,  # Save model every N batches\n",
        "    \"reset_freq_threshold\": 10**(-5.5),  # Frequency threshold for resetting neurons\n",
        "\n",
        "    # Wandb configuration\n",
        "    \"wandb_project\": \"mamba_autoencoder\",\n",
        "    \"wandb_name\": \"experiment_001\",\n",
        "\n",
        "    # Model specific (you might need to adjust these)\n",
        "    \"encoder_hidden_sizes\": [512, 256],  # Hidden layer sizes for encoder\n",
        "    \"decoder_hidden_sizes\": [256, 512],  # Hidden layer sizes for decoder\n",
        "    \"latent_dim\": 64,  # Dimension of the latent space\n",
        "}"
      ],
      "metadata": {
        "id": "NjprIIMd6H89"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset Preparation:"
      ],
      "metadata": {
        "id": "bNEPo2CFHs8H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# %%\n",
        "def shuffle_data(all_tokens):\n",
        "    print(\"Shuffled data\")\n",
        "    return all_tokens[torch.randperm(all_tokens.shape[0])]\n",
        "\n",
        "num_tokens=cfg['num_tokens']\n",
        "loading_data_first_time = False\n",
        "if loading_data_first_time:\n",
        "    data = load_dataset(\"NeelNanda/c4-code-tokenized-2b\", split=\"train\", cache_dir=\"/workspace/cache/\")\n",
        "    data.save_to_disk(\"/workspace/data/c4_code_tokenized_2b.hf\")\n",
        "    data.set_format(type=\"torch\", columns=[\"tokens\"])\n",
        "    limited_tokens = data[\"tokens\"][:num_tokens]\n",
        "    print(limited_tokens.shape)\n",
        "\n",
        "\n",
        "    limited_tokens_reshaped = einops.rearrange(limited_tokens, \"batch (x seq_len) -> (batch x) seq_len\", x=8, seq_len=128)\n",
        "    limited_tokens_reshaped[:, 0] = model.tokenizer.bos_token_id\n",
        "    limited_tokens_reshaped = limited_tokens_reshaped[torch.randperm(limited_tokens_reshaped.shape[0])]\n",
        "    torch.save(limited_tokens_reshaped, \"/workspace/data/c4_code_2e5_tokens_reshaped.pt\")\n",
        "\n",
        "    print(f\"Saved {limited_tokens_reshaped.shape[0]}\")\n",
        "else:\n",
        "    #data = datasets.load_from_disk(\"/workspace/data/c4_code_tokenized_2b.hf\")\n",
        "    all_tokens = torch.load(\"/workspace/data/c4_code_2e5_limited_tokens_reshaped.pt\")\n",
        "    all_tokens = shuffle_data(all_tokens)"
      ],
      "metadata": {
        "id": "GtNuBA2dUMhu",
        "outputId": "c0dd7965-58be-4548-acfa-7e22cc737c80",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shuffled data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_tokens = shuffle_data(all_tokens[:num_tokens,])\n",
        "print(all_tokens.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rRgTMLRH3FQn",
        "outputId": "a2628ed8-a6a3-4b44-af37-c0021696b11b"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shuffled data\n",
            "torch.Size([40000, 128])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset, DataLoader"
      ],
      "metadata": {
        "id": "g9cpVo2g5zzc"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TokenDataset(Dataset):\n",
        "    def __init__(self, tokens, max_tokens=int(2e5)):\n",
        "        self.tokens = tokens[:max_tokens]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.tokens)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.tokens[idx]\n",
        "\n",
        "# Load your data\n",
        "all_tokens = all_tokens.to(device)  # Move the data to the appropriate device\n",
        "\n",
        "# Create dataset and dataloader\n",
        "dataset = TokenDataset(all_tokens)\n",
        "dataloader = DataLoader(dataset, batch_size=cfg[\"batch_size\"], shuffle=True)"
      ],
      "metadata": {
        "id": "ziLNsKr653TB"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Autoencoder Class"
      ],
      "metadata": {
        "id": "EmRGmsqiooH2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SAVE_DIR = Path(\"/workspace/checkpoints\")\n",
        "class AutoEncoder(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        d_hidden = cfg[\"dict_size\"]\n",
        "        l1_coeff = cfg[\"l1_coeff\"]\n",
        "        dtype = DTYPES[cfg[\"enc_dtype\"]]\n",
        "        torch.manual_seed(cfg[\"seed\"])\n",
        "        self.W_enc = nn.Parameter(torch.nn.init.kaiming_uniform_(torch.empty(cfg[\"act_size\"], d_hidden, dtype=dtype)))\n",
        "        self.W_dec = nn.Parameter(torch.nn.init.kaiming_uniform_(torch.empty(d_hidden, cfg[\"act_size\"], dtype=dtype)))\n",
        "        self.b_enc = nn.Parameter(torch.zeros(d_hidden, dtype=dtype))\n",
        "        self.b_dec = nn.Parameter(torch.zeros(cfg[\"act_size\"], dtype=dtype))\n",
        "\n",
        "        self.W_dec.data[:] = self.W_dec / self.W_dec.norm(dim=-1, keepdim=True)\n",
        "\n",
        "        self.d_hidden = d_hidden\n",
        "        self.l1_coeff = l1_coeff\n",
        "\n",
        "        self.to(cfg[\"device\"])\n",
        "\n",
        "    def forward(self, x):\n",
        "        #print(f\"x.shape: {x.shape}\")\n",
        "        x_cent = x - self.b_dec\n",
        "        #print(f\"x_cent.shape: {x_cent.shape}\")\n",
        "        acts = F.relu(x_cent @ self.W_enc + self.b_enc)\n",
        "        #print(f\"acts.shape: {acts.shape}\")\n",
        "        x_reconstruct = acts @ self.W_dec + self.b_dec\n",
        "        #print(f\"x_reconstruct.shape: {x_reconstruct.shape}\")\n",
        "        l2_loss = (x_reconstruct.float() - x.float()).pow(2).sum(-1).mean()\n",
        "        #print(f\"l2_loss: {l2_loss}\")\n",
        "        l1_loss = self.l1_coeff * (acts.float().abs().sum())\n",
        "        #print(f\"l1_loss: {l1_loss}\")\n",
        "        loss = l2_loss + l1_loss\n",
        "        #print(f\"loss: {loss}\")\n",
        "        return loss, x_reconstruct, acts, l2_loss, l1_loss\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def make_decoder_weights_and_grad_unit_norm(self):\n",
        "        W_dec_normed = self.W_dec / self.W_dec.norm(dim=-1, keepdim=True)\n",
        "        W_dec_grad_proj = (self.W_dec.grad * W_dec_normed).sum(-1, keepdim=True) * W_dec_normed\n",
        "        self.W_dec.grad -= W_dec_grad_proj\n",
        "        # Bugfix(?) for ensuring W_dec retains unit norm, this was not there when I trained my original autoencoders.\n",
        "        self.W_dec.data = W_dec_normed\n",
        "\n",
        "    def get_version(self):\n",
        "        version_list = [int(file.name.split(\".\")[0]) for file in list(SAVE_DIR.iterdir()) if \"pt\" in str(file)]\n",
        "        if len(version_list):\n",
        "            return 1+max(version_list)\n",
        "        else:\n",
        "            return 0\n",
        "\n",
        "    def save(self):\n",
        "        version = self.get_version()\n",
        "        torch.save(self.state_dict(), SAVE_DIR/(str(version)+\".pt\"))\n",
        "        with open(SAVE_DIR/(str(version)+\"_cfg.json\"), \"w\") as f:\n",
        "            json.dump(cfg, f)\n",
        "        print(\"Saved as version\", version)\n",
        "\n",
        "    @classmethod\n",
        "    def load(cls, version):\n",
        "        cfg = (json.load(open(SAVE_DIR/(str(version)+\"_cfg.json\"), \"r\")))\n",
        "        pprint.pprint(cfg)\n",
        "        self = cls(cfg=cfg)\n",
        "        self.load_state_dict(torch.load(SAVE_DIR/(str(version)+\".pt\")))\n",
        "        return self\n",
        "\n",
        "    @classmethod\n",
        "    def load_from_hf(cls, version):\n",
        "        \"\"\"\n",
        "        Loads the saved autoencoder from HuggingFace.\n",
        "\n",
        "        Version is expected to be an int, or \"run1\" or \"run2\"\n",
        "\n",
        "        version 25 is the final checkpoint of the first autoencoder run,\n",
        "        version 47 is the final checkpoint of the second autoencoder run.\n",
        "        \"\"\"\n",
        "        if version==\"run1\":\n",
        "            version = 25\n",
        "        elif version==\"run2\":\n",
        "            version = 47\n",
        "\n",
        "        cfg = utils.download_file_from_hf(\"NeelNanda/sparse_autoencoder\", f\"{version}_cfg.json\")\n",
        "        pprint.pprint(cfg)\n",
        "        self = cls(cfg=cfg)\n",
        "        self.load_state_dict(utils.download_file_from_hf(\"NeelNanda/sparse_autoencoder\", f\"{version}.pt\", force_is_torch=True))\n",
        "        return self"
      ],
      "metadata": {
        "id": "MKnPU7TqOZQ9"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Utilities for Training"
      ],
      "metadata": {
        "id": "wUFJl2D74B8M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SEED = cfg[\"seed\"]\n",
        "GENERATOR = torch.manual_seed(SEED)\n",
        "DTYPES = {\"fp32\": torch.float32, \"fp16\": torch.float16, \"bf16\": torch.bfloat16}\n",
        "np.random.seed(SEED)\n",
        "random.seed(SEED)\n",
        "torch.set_grad_enabled(True)\n",
        "\n",
        "n_layers = model.cfg.n_layers\n",
        "d_model = model.cfg.d_model\n",
        "# %%\n",
        "@torch.no_grad()\n",
        "def get_acts(tokens, batch_size=1024):\n",
        "    outputs, cache = model.run_with_cache(tokens,\n",
        "                                          fast_ssm=True,\n",
        "                                          fast_conv=True,\n",
        "                                          warn_disabled_hooks=False,\n",
        "                                          names_filter=cfg[\"act_name\"])\n",
        "    acts = cache[cfg[\"act_name\"]]\n",
        "    del outputs, cache\n",
        "    torch.cuda.empty_cache()\n",
        "    gc.collect()\n",
        "    acts = acts.reshape(-1, acts.shape[-1])\n",
        "    subsample = torch.randperm(acts.shape[0], generator=GENERATOR)[:batch_size]\n",
        "    subsampled_acts = acts[subsample, :]\n",
        "    return subsampled_acts, acts\n",
        "# sub, acts = get_acts(torch.arange(20).reshape(2, 10), batch_size=3)\n",
        "# sub.shape, acts.shape\n",
        "# %%"
      ],
      "metadata": {
        "id": "zCe2wa85S_2E"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def replacement_hook(pre_linear, hook, encoder):\n",
        "    pre_linear_reconstr = encoder(pre_linear)[1]\n",
        "    return pre_linear_reconstr\n",
        "\n",
        "def mean_ablate_hook(pre_linear, hook):\n",
        "    pre_linear[:] = pre_linear.mean([0, 1])\n",
        "    return pre_linear\n",
        "\n",
        "def zero_ablate_hook(pre_linear, hook):\n",
        "    pre_linear[:] = 0.\n",
        "    return pre_linear\n",
        "\n",
        "@torch.no_grad()\n",
        "def get_recons_loss(num_batches=5, local_encoder=None):\n",
        "    if local_encoder is None:\n",
        "        local_encoder = encoder\n",
        "    loss_list = []\n",
        "    for i in range(num_batches):\n",
        "        tokens = all_tokens[torch.randperm(len(all_tokens))[:cfg[\"model_batch_size\"]]]\n",
        "        loss = model(tokens, return_type=\"loss\")\n",
        "        recons_loss = model.run_with_hooks(tokens, return_type=\"loss\",\n",
        "                                           fast_ssm=True,\n",
        "                                           fast_conv=True,\n",
        "                                           fwd_hooks=[(cfg[\"act_name\"], partial(replacement_hook, encoder=local_encoder))])\n",
        "        # mean_abl_loss = model.run_with_hooks(tokens, return_type=\"loss\", fwd_hooks=[(cfg[\"act_name\"], mean_ablate_hook)])\n",
        "        zero_abl_loss = model.run_with_hooks(tokens, return_type=\"loss\",\n",
        "                                             fast_ssm=True,\n",
        "                                             fast_conv=True,\n",
        "                                             fwd_hooks=[(cfg[\"act_name\"], zero_ablate_hook)])\n",
        "        loss_list.append((loss, recons_loss, zero_abl_loss))\n",
        "    losses = torch.tensor(loss_list)\n",
        "    loss, recons_loss, zero_abl_loss = losses.mean(0).tolist()\n",
        "\n",
        "    print(loss, recons_loss, zero_abl_loss)\n",
        "    score = ((zero_abl_loss - recons_loss)/(zero_abl_loss - loss))\n",
        "    print(f\"{score:.2%}\")\n",
        "    # print(f\"{((zero_abl_loss - mean_abl_loss)/(zero_abl_loss - loss)).item():.2%}\")\n",
        "    return score, loss, recons_loss, zero_abl_loss\n",
        "# print(get_recons_loss())\n",
        "\n",
        "# %%\n",
        "# Frequency\n",
        "@torch.no_grad()\n",
        "def get_freqs(num_batches=25, local_encoder=None):\n",
        "    if local_encoder is None:\n",
        "        local_encoder = encoder\n",
        "    act_freq_scores = torch.zeros(local_encoder.d_hidden, dtype=torch.float32).to(cfg[\"device\"])\n",
        "    total = 0\n",
        "    for i in tqdm(range(num_batches)):\n",
        "        tokens = all_tokens[torch.randperm(len(all_tokens))[:cfg[\"model_batch_size\"]]]\n",
        "\n",
        "        _, cache = model.run_with_cache(tokens, names_filter=cfg[\"act_name\"], fast_ssm=True, fast_conv=True, warn_disabled_hooks=False)\n",
        "        acts = cache[cfg[\"act_name\"]]\n",
        "        acts = acts.reshape(-1, cfg[\"act_size\"])\n",
        "\n",
        "        hidden = local_encoder(acts)[2]\n",
        "\n",
        "        act_freq_scores += (hidden > 0).sum(0)\n",
        "        total+=hidden.shape[0]\n",
        "    act_freq_scores /= total\n",
        "    num_dead = (act_freq_scores==0).float().mean()\n",
        "    print(\"Num dead\", num_dead)\n",
        "    return act_freq_scores\n",
        "# %%\n",
        "@torch.no_grad()\n",
        "def re_init(indices, encoder):\n",
        "    new_W_enc = (torch.nn.init.kaiming_uniform_(torch.zeros_like(encoder.W_enc)))\n",
        "    new_W_dec = (torch.nn.init.kaiming_uniform_(torch.zeros_like(encoder.W_dec)))\n",
        "    new_b_enc = (torch.zeros_like(encoder.b_enc))\n",
        "    print(new_W_dec.shape, new_W_enc.shape, new_b_enc.shape)\n",
        "    encoder.W_enc.data[:, indices] = new_W_enc[:, indices]\n",
        "    encoder.W_dec.data[indices, :] = new_W_dec[indices, :]\n",
        "    encoder.b_enc.data[indices] = new_b_enc[indices]"
      ],
      "metadata": {
        "id": "lve-_edPVmHS"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lim_tokens = all_tokens[:32]\n",
        "print(lim_tokens.shape)\n",
        "\n",
        "outputs, MambaActs = model.run_with_cache(\n",
        "                                        lim_tokens,\n",
        "                                        fast_ssm=True,\n",
        "                                        fast_conv=True,\n",
        "                                        warn_disabled_hooks=False\n",
        "                                        )\n",
        "\n",
        "acts = MambaActs[cfg[\"act_name\"]]\n",
        "print(acts.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TIpc0M3Sa3p7",
        "outputId": "b2c945b5-88de-42fc-d144-9341c2efedc6"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32, 128])\n",
            "torch.Size([32, 128, 768])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "del outputs, MambaActs\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LZUI8z0ubBYB",
        "outputId": "57ade557-673f-4cc6-8b23-850622898935"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training Run"
      ],
      "metadata": {
        "id": "udkJM87H4DHF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# %%\n",
        "encoder = AutoEncoder(cfg)"
      ],
      "metadata": {
        "id": "cezNrtJCK54p"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Wandb Args:\n",
        "wandb_args = {\n",
        "  \"wandb_project\": \"mamba-sae\",\n",
        "  \"wandb_name\": None,\n",
        "}\n",
        "\n",
        "try:\n",
        "    wandb.init(\n",
        "        project=wandb_args[\"wandb_project\"],\n",
        "        name=wandb_args[\"wandb_name\"],\n",
        "    )\n",
        "\n",
        "    num_batches = len(dataloader)\n",
        "    print(f\"Number of tokens: {cfg['num_tokens']}\")\n",
        "    print(f\"Batch size: {cfg['batch_size']}\")\n",
        "    print(f\"Number of batches: {num_batches}\")\n",
        "\n",
        "    encoder_optim = torch.optim.Adam(encoder.parameters(), lr=cfg[\"lr\"], betas=(cfg[\"beta1\"], cfg[\"beta2\"]))\n",
        "    recons_scores = []\n",
        "    act_freq_scores_list = []\n",
        "\n",
        "    for epoch in range(cfg[\"num_epochs\"]):  # Add an outer loop for epochs if needed\n",
        "        for i, tokens in enumerate(tqdm(dataloader)):\n",
        "            tokens = tokens.to(device)\n",
        "\n",
        "            sub_acts = get_acts(tokens, 16)[1]\n",
        "            acts = sub_acts\n",
        "\n",
        "            loss, x_reconstruct, mid_acts, l2_loss, l1_loss = encoder(acts)\n",
        "            loss.backward()\n",
        "\n",
        "            encoder.make_decoder_weights_and_grad_unit_norm()\n",
        "            encoder_optim.step()\n",
        "            encoder_optim.zero_grad()\n",
        "\n",
        "            loss_dict = {\"loss\": loss.item(), \"l2_loss\": l2_loss.item(), \"l1_loss\": l1_loss.item()}\n",
        "            del loss, x_reconstruct, mid_acts, l2_loss, l1_loss, acts\n",
        "            torch.cuda.empty_cache()\n",
        "            gc.collect()\n",
        "\n",
        "            \"\"\"\n",
        "            print(\"torch.cuda.memory_allocated: %fGB\"%(torch.cuda.memory_allocated(0)/1024/1024/1024))\n",
        "            print(\"torch.cuda.memory_reserved: %fGB\"%(torch.cuda.memory_reserved(0)/1024/1024/1024))\n",
        "            print(\"torch.cuda.max_memory_reserved: %fGB\"%(torch.cuda.max_memory_reserved(0)/1024/1024/1024))\n",
        "            \"\"\"\n",
        "\n",
        "            if (i + 1) % cfg[\"log_every\"] == 0:\n",
        "                wandb.log(loss_dict)\n",
        "                print(loss_dict)\n",
        "\n",
        "            if (i + 1) % cfg[\"recons_every\"] == 0:\n",
        "                x = get_recons_loss(local_encoder=encoder)\n",
        "                print(\"Reconstruction:\", x)\n",
        "                recons_scores.append(x[0])\n",
        "                freqs = get_freqs(5, local_encoder=encoder)\n",
        "                act_freq_scores_list.append(freqs)\n",
        "                wandb.log({\n",
        "                    \"recons_score\": x[0],\n",
        "                    \"dead\": (freqs==0).float().mean().item(),\n",
        "                    \"below_1e-6\": (freqs<1e-6).float().mean().item(),\n",
        "                    \"below_1e-5\": (freqs<1e-5).float().mean().item(),\n",
        "                })\n",
        "\n",
        "            if (i + 1) % cfg[\"save_every\"] == 0:\n",
        "                encoder.save()\n",
        "                wandb.log({\"reset_neurons\": 0.0})\n",
        "                freqs = get_freqs(50, local_encoder=encoder)\n",
        "                to_be_reset = (freqs < cfg[\"reset_freq_threshold\"])\n",
        "                print(\"Resetting neurons!\", to_be_reset.sum())\n",
        "                re_init(to_be_reset, encoder)\n",
        "\n",
        "finally:\n",
        "    encoder.save()"
      ],
      "metadata": {
        "id": "7jY4fo3uVooQ",
        "outputId": "09e0de7d-5314-45f4-995a-334c927d1c48",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "58d4136a18504291bb6162b29a8d088e",
            "de0dbc1b23264c0e954db73a809b7b1a",
            "34a0e383f57c49e394abcec2a51e60a8",
            "75ec369fa7af48b4bee348227f5a8a2c",
            "0ba7c4538cbe49b28cb0909004654a15",
            "296cb82af3d54cdb99e519f853a540c1",
            "9b57174460ae48b6b89c8f0ec8203958",
            "fe4e854d65a248c4a3ce1ad88c509be3"
          ]
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Finishing last run (ID:cxitlaza) before initializing another..."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='0.013 MB of 0.013 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "58d4136a18504291bb6162b29a8d088e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">celestial-resonance-41</strong> at: <a href='https://wandb.ai/amantima/mamba-sae/runs/cxitlaza' target=\"_blank\">https://wandb.ai/amantima/mamba-sae/runs/cxitlaza</a><br/> View project at: <a href='https://wandb.ai/amantima/mamba-sae' target=\"_blank\">https://wandb.ai/amantima/mamba-sae</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20240830_224251-cxitlaza/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Successfully finished last run (ID:cxitlaza). Initializing new run:<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.17.8"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20240830_224320-y3r9k6ke</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/amantima/mamba-sae/runs/y3r9k6ke' target=\"_blank\">sunny-snowflake-42</a></strong> to <a href='https://wandb.ai/amantima/mamba-sae' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/amantima/mamba-sae' target=\"_blank\">https://wandb.ai/amantima/mamba-sae</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/amantima/mamba-sae/runs/y3r9k6ke' target=\"_blank\">https://wandb.ai/amantima/mamba-sae/runs/y3r9k6ke</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of tokens: 40000\n",
            "Batch size: 32\n",
            "Number of batches: 1250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  8%|▊         | 100/1250 [01:15<14:28,  1.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'loss': 204.88198852539062, 'l2_loss': 50.08789825439453, 'l1_loss': 154.79409790039062}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 16%|█▌        | 200/1250 [02:31<13:06,  1.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'loss': 178.07774353027344, 'l2_loss': 38.30793762207031, 'l1_loss': 139.76980590820312}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 24%|██▍       | 300/1250 [03:46<11:55,  1.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'loss': 170.08145141601562, 'l2_loss': 34.49451446533203, 'l1_loss': 135.58694458007812}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 32%|███▏      | 400/1250 [05:01<10:32,  1.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'loss': 173.08322143554688, 'l2_loss': 35.372093200683594, 'l1_loss': 137.71112060546875}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 40%|███▉      | 499/1250 [06:15<09:24,  1.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'loss': 164.3024139404297, 'l2_loss': 32.7568473815918, 'l1_loss': 131.54556274414062}\n",
            "9.475272178649902 9.502836227416992 10.825362205505371\n",
            "97.96%\n",
            "Reconstruction: (0.9795835476014217, 9.475272178649902, 9.502836227416992, 10.825362205505371)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
            " 20%|██        | 1/5 [00:00<00:01,  2.45it/s]\u001b[A\n",
            " 60%|██████    | 3/5 [00:00<00:00,  3.78it/s]\u001b[A\n",
            " 80%|████████  | 4/5 [00:01<00:00,  3.18it/s]\u001b[A\n",
            "100%|██████████| 5/5 [00:01<00:00,  3.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num dead tensor(0.3737, device='cuda:0')\n",
            "Saved as version 44\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
            "  4%|▍         | 2/50 [00:00<00:10,  4.79it/s]\u001b[A\n",
            "  6%|▌         | 3/50 [00:00<00:13,  3.54it/s]\u001b[A\n",
            "  8%|▊         | 4/50 [00:01<00:15,  3.01it/s]\u001b[A\n",
            " 10%|█         | 5/50 [00:01<00:15,  2.84it/s]\u001b[A\n",
            " 12%|█▏        | 6/50 [00:02<00:16,  2.71it/s]\u001b[A\n",
            " 14%|█▍        | 7/50 [00:02<00:16,  2.65it/s]\u001b[A\n",
            " 16%|█▌        | 8/50 [00:02<00:15,  2.63it/s]\u001b[A\n",
            " 18%|█▊        | 9/50 [00:03<00:15,  2.57it/s]\u001b[A\n",
            " 20%|██        | 10/50 [00:03<00:15,  2.57it/s]\u001b[A\n",
            " 22%|██▏       | 11/50 [00:03<00:15,  2.56it/s]\u001b[A\n",
            " 24%|██▍       | 12/50 [00:04<00:14,  2.55it/s]\u001b[A\n",
            " 26%|██▌       | 13/50 [00:04<00:14,  2.55it/s]\u001b[A\n",
            " 28%|██▊       | 14/50 [00:05<00:14,  2.53it/s]\u001b[A\n",
            " 30%|███       | 15/50 [00:05<00:13,  2.53it/s]\u001b[A\n",
            " 32%|███▏      | 16/50 [00:05<00:13,  2.51it/s]\u001b[A\n",
            " 34%|███▍      | 17/50 [00:06<00:13,  2.53it/s]\u001b[A\n",
            " 36%|███▌      | 18/50 [00:06<00:12,  2.53it/s]\u001b[A\n",
            " 38%|███▊      | 19/50 [00:07<00:12,  2.52it/s]\u001b[A\n",
            " 40%|████      | 20/50 [00:07<00:11,  2.53it/s]\u001b[A\n",
            " 42%|████▏     | 21/50 [00:07<00:11,  2.52it/s]\u001b[A\n",
            " 44%|████▍     | 22/50 [00:08<00:11,  2.52it/s]\u001b[A\n",
            " 46%|████▌     | 23/50 [00:08<00:10,  2.51it/s]\u001b[A\n",
            " 48%|████▊     | 24/50 [00:09<00:10,  2.51it/s]\u001b[A\n",
            " 50%|█████     | 25/50 [00:09<00:09,  2.52it/s]\u001b[A\n",
            " 52%|█████▏    | 26/50 [00:09<00:09,  2.52it/s]\u001b[A\n",
            " 54%|█████▍    | 27/50 [00:10<00:09,  2.53it/s]\u001b[A\n",
            " 56%|█████▌    | 28/50 [00:10<00:08,  2.52it/s]\u001b[A\n",
            " 58%|█████▊    | 29/50 [00:11<00:08,  2.53it/s]\u001b[A\n",
            " 60%|██████    | 30/50 [00:11<00:07,  2.52it/s]\u001b[A\n",
            " 62%|██████▏   | 31/50 [00:11<00:07,  2.52it/s]\u001b[A\n",
            " 64%|██████▍   | 32/50 [00:12<00:07,  2.54it/s]\u001b[A\n",
            " 66%|██████▌   | 33/50 [00:12<00:06,  2.52it/s]\u001b[A\n",
            " 68%|██████▊   | 34/50 [00:13<00:06,  2.53it/s]\u001b[A\n",
            " 70%|███████   | 35/50 [00:13<00:05,  2.53it/s]\u001b[A\n",
            " 72%|███████▏  | 36/50 [00:13<00:05,  2.53it/s]\u001b[A\n",
            " 74%|███████▍  | 37/50 [00:14<00:05,  2.53it/s]\u001b[A\n",
            " 76%|███████▌  | 38/50 [00:14<00:04,  2.52it/s]\u001b[A\n",
            " 78%|███████▊  | 39/50 [00:15<00:04,  2.52it/s]\u001b[A\n",
            " 80%|████████  | 40/50 [00:15<00:03,  2.52it/s]\u001b[A\n",
            " 82%|████████▏ | 41/50 [00:15<00:03,  2.53it/s]\u001b[A\n",
            " 84%|████████▍ | 42/50 [00:16<00:03,  2.53it/s]\u001b[A\n",
            " 86%|████████▌ | 43/50 [00:16<00:02,  2.52it/s]\u001b[A\n",
            " 88%|████████▊ | 44/50 [00:17<00:02,  2.53it/s]\u001b[A\n",
            " 90%|█████████ | 45/50 [00:17<00:01,  2.53it/s]\u001b[A\n",
            " 92%|█████████▏| 46/50 [00:17<00:01,  2.53it/s]\u001b[A\n",
            " 94%|█████████▍| 47/50 [00:18<00:01,  2.53it/s]\u001b[A\n",
            " 96%|█████████▌| 48/50 [00:18<00:00,  2.52it/s]\u001b[A\n",
            " 98%|█████████▊| 49/50 [00:19<00:00,  2.53it/s]\u001b[A\n",
            "100%|██████████| 50/50 [00:19<00:00,  2.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num dead "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|████      | 500/1250 [06:47<2:05:50, 10.07s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.1094, device='cuda:0')\n",
            "Resetting neurons! tensor(168, device='cuda:0')\n",
            "torch.Size([1536, 768]) torch.Size([768, 1536]) torch.Size([1536])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 48%|████▊     | 600/1250 [08:02<08:05,  1.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'loss': 166.66751098632812, 'l2_loss': 34.73277282714844, 'l1_loss': 131.9347381591797}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 56%|█████▌    | 700/1250 [09:17<06:53,  1.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'loss': 163.65097045898438, 'l2_loss': 34.84036636352539, 'l1_loss': 128.81060791015625}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 64%|██████▍   | 800/1250 [10:32<05:38,  1.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'loss': 163.880126953125, 'l2_loss': 32.230712890625, 'l1_loss': 131.6494140625}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 72%|███████▏  | 900/1250 [11:48<04:22,  1.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'loss': 163.4452362060547, 'l2_loss': 31.602737426757812, 'l1_loss': 131.84249877929688}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 80%|███████▉  | 999/1250 [13:02<03:08,  1.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'loss': 166.22894287109375, 'l2_loss': 34.34717559814453, 'l1_loss': 131.88177490234375}\n",
            "9.441526412963867 9.511152267456055 10.825362205505371\n",
            "94.97%\n",
            "Reconstruction: (0.9496863321013579, 9.441526412963867, 9.511152267456055, 10.825362205505371)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
            " 40%|████      | 2/5 [00:00<00:00,  4.51it/s]\u001b[A\n",
            " 60%|██████    | 3/5 [00:00<00:00,  3.47it/s]\u001b[A\n",
            " 80%|████████  | 4/5 [00:01<00:00,  3.00it/s]\u001b[A\n",
            "100%|██████████| 5/5 [00:01<00:00,  3.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num dead tensor(0.6139, device='cuda:0')\n",
            "Saved as version 45\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
            "  4%|▍         | 2/50 [00:00<00:10,  4.76it/s]\u001b[A\n",
            "  6%|▌         | 3/50 [00:00<00:13,  3.52it/s]\u001b[A\n",
            "  8%|▊         | 4/50 [00:01<00:15,  3.04it/s]\u001b[A\n",
            " 10%|█         | 5/50 [00:01<00:15,  2.86it/s]\u001b[A\n",
            " 12%|█▏        | 6/50 [00:02<00:16,  2.73it/s]\u001b[A\n",
            " 14%|█▍        | 7/50 [00:02<00:16,  2.67it/s]\u001b[A\n",
            " 16%|█▌        | 8/50 [00:02<00:15,  2.64it/s]\u001b[A\n",
            " 18%|█▊        | 9/50 [00:03<00:15,  2.59it/s]\u001b[A\n",
            " 20%|██        | 10/50 [00:03<00:15,  2.57it/s]\u001b[A\n",
            " 22%|██▏       | 11/50 [00:03<00:15,  2.56it/s]\u001b[A\n",
            " 24%|██▍       | 12/50 [00:04<00:14,  2.54it/s]\u001b[A\n",
            " 26%|██▌       | 13/50 [00:04<00:14,  2.55it/s]\u001b[A\n",
            " 28%|██▊       | 14/50 [00:05<00:14,  2.55it/s]\u001b[A\n",
            " 30%|███       | 15/50 [00:05<00:13,  2.55it/s]\u001b[A\n",
            " 32%|███▏      | 16/50 [00:05<00:13,  2.54it/s]\u001b[A\n",
            " 34%|███▍      | 17/50 [00:06<00:13,  2.53it/s]\u001b[A\n",
            " 36%|███▌      | 18/50 [00:06<00:12,  2.52it/s]\u001b[A\n",
            " 38%|███▊      | 19/50 [00:07<00:12,  2.53it/s]\u001b[A\n",
            " 40%|████      | 20/50 [00:07<00:11,  2.52it/s]\u001b[A\n",
            " 42%|████▏     | 21/50 [00:07<00:11,  2.54it/s]\u001b[A\n",
            " 44%|████▍     | 22/50 [00:08<00:11,  2.52it/s]\u001b[A\n",
            " 46%|████▌     | 23/50 [00:08<00:10,  2.53it/s]\u001b[A\n",
            " 48%|████▊     | 24/50 [00:09<00:10,  2.53it/s]\u001b[A\n",
            " 50%|█████     | 25/50 [00:09<00:09,  2.53it/s]\u001b[A\n",
            " 52%|█████▏    | 26/50 [00:09<00:09,  2.54it/s]\u001b[A\n",
            " 54%|█████▍    | 27/50 [00:10<00:09,  2.53it/s]\u001b[A\n",
            " 56%|█████▌    | 28/50 [00:10<00:08,  2.53it/s]\u001b[A\n",
            " 58%|█████▊    | 29/50 [00:11<00:08,  2.53it/s]\u001b[A\n",
            " 60%|██████    | 30/50 [00:11<00:07,  2.53it/s]\u001b[A\n",
            " 62%|██████▏   | 31/50 [00:11<00:07,  2.52it/s]\u001b[A\n",
            " 64%|██████▍   | 32/50 [00:12<00:07,  2.52it/s]\u001b[A\n",
            " 66%|██████▌   | 33/50 [00:12<00:06,  2.53it/s]\u001b[A\n",
            " 68%|██████▊   | 34/50 [00:13<00:06,  2.55it/s]\u001b[A\n",
            " 70%|███████   | 35/50 [00:13<00:05,  2.52it/s]\u001b[A\n",
            " 72%|███████▏  | 36/50 [00:13<00:05,  2.54it/s]\u001b[A\n",
            " 74%|███████▍  | 37/50 [00:14<00:05,  2.53it/s]\u001b[A\n",
            " 76%|███████▌  | 38/50 [00:14<00:04,  2.54it/s]\u001b[A\n",
            " 78%|███████▊  | 39/50 [00:15<00:04,  2.54it/s]\u001b[A\n",
            " 80%|████████  | 40/50 [00:15<00:03,  2.53it/s]\u001b[A\n",
            " 82%|████████▏ | 41/50 [00:15<00:03,  2.54it/s]\u001b[A\n",
            " 84%|████████▍ | 42/50 [00:16<00:03,  2.53it/s]\u001b[A\n",
            " 86%|████████▌ | 43/50 [00:16<00:02,  2.54it/s]\u001b[A\n",
            " 88%|████████▊ | 44/50 [00:17<00:02,  2.54it/s]\u001b[A\n",
            " 90%|█████████ | 45/50 [00:17<00:01,  2.54it/s]\u001b[A\n",
            " 92%|█████████▏| 46/50 [00:17<00:01,  2.53it/s]\u001b[A\n",
            " 94%|█████████▍| 47/50 [00:18<00:01,  2.53it/s]\u001b[A\n",
            " 96%|█████████▌| 48/50 [00:18<00:00,  2.54it/s]\u001b[A\n",
            " 98%|█████████▊| 49/50 [00:18<00:00,  2.54it/s]\u001b[A\n",
            "100%|██████████| 50/50 [00:19<00:00,  2.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num dead "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|████████  | 1000/1250 [13:33<41:45, 10.02s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.4264, device='cuda:0')\n",
            "Resetting neurons! tensor(655, device='cuda:0')\n",
            "torch.Size([1536, 768]) torch.Size([768, 1536]) torch.Size([1536])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 88%|████████▊ | 1100/1250 [14:48<01:52,  1.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'loss': 167.40994262695312, 'l2_loss': 36.55908966064453, 'l1_loss': 130.85086059570312}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 96%|█████████▌| 1200/1250 [16:03<00:37,  1.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'loss': 163.40879821777344, 'l2_loss': 35.63167953491211, 'l1_loss': 127.77711486816406}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1250/1250 [16:41<00:00,  1.25it/s]\n",
            "  8%|▊         | 100/1250 [01:14<14:14,  1.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'loss': 158.4322509765625, 'l2_loss': 30.363689422607422, 'l1_loss': 128.0685577392578}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 16%|█▌        | 200/1250 [02:29<13:09,  1.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'loss': 158.50927734375, 'l2_loss': 32.23187255859375, 'l1_loss': 126.27740478515625}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 24%|██▍       | 300/1250 [03:44<11:50,  1.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'loss': 157.81356811523438, 'l2_loss': 31.87213134765625, 'l1_loss': 125.9414291381836}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 32%|███▏      | 400/1250 [04:59<10:37,  1.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'loss': 164.72000122070312, 'l2_loss': 35.16238784790039, 'l1_loss': 129.5576171875}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 40%|███▉      | 499/1250 [06:13<09:20,  1.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'loss': 157.7126007080078, 'l2_loss': 32.61067581176758, 'l1_loss': 125.1019287109375}\n",
            "9.3403902053833 9.459783554077148 10.825362205505371\n",
            "91.96%\n",
            "Reconstruction: (0.9195989226167005, 9.3403902053833, 9.459783554077148, 10.825362205505371)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
            " 40%|████      | 2/5 [00:00<00:00,  4.45it/s]\u001b[A\n",
            " 60%|██████    | 3/5 [00:00<00:00,  3.44it/s]\u001b[A\n",
            " 80%|████████  | 4/5 [00:01<00:00,  2.99it/s]\u001b[A\n",
            "100%|██████████| 5/5 [00:01<00:00,  3.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num dead tensor(0.4694, device='cuda:0')\n",
            "Saved as version 46\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
            "  4%|▍         | 2/50 [00:00<00:10,  4.64it/s]\u001b[A\n",
            "  6%|▌         | 3/50 [00:00<00:13,  3.48it/s]\u001b[A\n",
            "  8%|▊         | 4/50 [00:01<00:15,  3.02it/s]\u001b[A\n",
            " 10%|█         | 5/50 [00:01<00:15,  2.84it/s]\u001b[A\n",
            " 12%|█▏        | 6/50 [00:02<00:16,  2.72it/s]\u001b[A\n",
            " 14%|█▍        | 7/50 [00:02<00:16,  2.65it/s]\u001b[A\n",
            " 16%|█▌        | 8/50 [00:02<00:16,  2.62it/s]\u001b[A\n",
            " 18%|█▊        | 9/50 [00:03<00:15,  2.59it/s]\u001b[A\n",
            " 20%|██        | 10/50 [00:03<00:15,  2.57it/s]\u001b[A\n",
            " 22%|██▏       | 11/50 [00:03<00:15,  2.56it/s]\u001b[A\n",
            " 24%|██▍       | 12/50 [00:04<00:14,  2.54it/s]\u001b[A\n",
            " 26%|██▌       | 13/50 [00:04<00:14,  2.54it/s]\u001b[A\n",
            " 28%|██▊       | 14/50 [00:05<00:14,  2.53it/s]\u001b[A\n",
            " 30%|███       | 15/50 [00:05<00:13,  2.53it/s]\u001b[A\n",
            " 32%|███▏      | 16/50 [00:05<00:13,  2.51it/s]\u001b[A\n",
            " 34%|███▍      | 17/50 [00:06<00:13,  2.53it/s]\u001b[A\n",
            " 36%|███▌      | 18/50 [00:06<00:12,  2.52it/s]\u001b[A\n",
            " 38%|███▊      | 19/50 [00:07<00:12,  2.52it/s]\u001b[A\n",
            " 40%|████      | 20/50 [00:07<00:11,  2.53it/s]\u001b[A\n",
            " 42%|████▏     | 21/50 [00:07<00:11,  2.53it/s]\u001b[A\n",
            " 44%|████▍     | 22/50 [00:08<00:11,  2.52it/s]\u001b[A\n",
            " 46%|████▌     | 23/50 [00:08<00:10,  2.53it/s]\u001b[A\n",
            " 48%|████▊     | 24/50 [00:09<00:10,  2.53it/s]\u001b[A\n",
            " 50%|█████     | 25/50 [00:09<00:09,  2.52it/s]\u001b[A\n",
            " 52%|█████▏    | 26/50 [00:09<00:09,  2.52it/s]\u001b[A\n",
            " 54%|█████▍    | 27/50 [00:10<00:09,  2.53it/s]\u001b[A\n",
            " 56%|█████▌    | 28/50 [00:10<00:08,  2.53it/s]\u001b[A\n",
            " 58%|█████▊    | 29/50 [00:11<00:08,  2.52it/s]\u001b[A\n",
            " 60%|██████    | 30/50 [00:11<00:07,  2.53it/s]\u001b[A\n",
            " 62%|██████▏   | 31/50 [00:11<00:07,  2.52it/s]\u001b[A\n",
            " 64%|██████▍   | 32/50 [00:12<00:07,  2.51it/s]\u001b[A\n",
            " 66%|██████▌   | 33/50 [00:12<00:06,  2.53it/s]\u001b[A\n",
            " 68%|██████▊   | 34/50 [00:13<00:06,  2.52it/s]\u001b[A\n",
            " 70%|███████   | 35/50 [00:13<00:05,  2.53it/s]\u001b[A\n",
            " 72%|███████▏  | 36/50 [00:13<00:05,  2.51it/s]\u001b[A\n",
            " 74%|███████▍  | 37/50 [00:14<00:05,  2.53it/s]\u001b[A\n",
            " 76%|███████▌  | 38/50 [00:14<00:04,  2.52it/s]\u001b[A\n",
            " 78%|███████▊  | 39/50 [00:15<00:04,  2.52it/s]\u001b[A\n",
            " 80%|████████  | 40/50 [00:15<00:03,  2.53it/s]\u001b[A\n",
            " 82%|████████▏ | 41/50 [00:15<00:03,  2.50it/s]\u001b[A\n",
            " 84%|████████▍ | 42/50 [00:16<00:03,  2.52it/s]\u001b[A\n",
            " 86%|████████▌ | 43/50 [00:16<00:02,  2.54it/s]\u001b[A\n",
            " 88%|████████▊ | 44/50 [00:17<00:02,  2.51it/s]\u001b[A\n",
            " 90%|█████████ | 45/50 [00:17<00:01,  2.53it/s]\u001b[A\n",
            " 92%|█████████▏| 46/50 [00:17<00:01,  2.53it/s]\u001b[A\n",
            " 94%|█████████▍| 47/50 [00:18<00:01,  2.53it/s]\u001b[A\n",
            " 96%|█████████▌| 48/50 [00:18<00:00,  2.53it/s]\u001b[A\n",
            " 98%|█████████▊| 49/50 [00:19<00:00,  2.53it/s]\u001b[A\n",
            "100%|██████████| 50/50 [00:19<00:00,  2.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num dead "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|████      | 500/1250 [06:45<2:05:34, 10.05s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.2292, device='cuda:0')\n",
            "Resetting neurons! tensor(352, device='cuda:0')\n",
            "torch.Size([1536, 768]) torch.Size([768, 1536]) torch.Size([1536])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 48%|████▊     | 600/1250 [08:00<08:09,  1.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'loss': 159.95684814453125, 'l2_loss': 33.66575241088867, 'l1_loss': 126.29109954833984}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 56%|█████▌    | 700/1250 [09:14<06:50,  1.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'loss': 157.31640625, 'l2_loss': 32.18115997314453, 'l1_loss': 125.13524627685547}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 64%|██████▍   | 800/1250 [10:29<05:36,  1.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'loss': 156.83468627929688, 'l2_loss': 33.05988311767578, 'l1_loss': 123.77479553222656}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 72%|███████▏  | 900/1250 [11:44<04:22,  1.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'loss': 157.30479431152344, 'l2_loss': 31.66326332092285, 'l1_loss': 125.64152526855469}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 80%|███████▉  | 999/1250 [12:58<03:08,  1.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'loss': 157.253662109375, 'l2_loss': 32.628509521484375, 'l1_loss': 124.62516021728516}\n",
            "9.686169624328613 9.614639282226562 10.825362205505371\n",
            "106.28%\n",
            "Reconstruction: (1.06279038617699, 9.686169624328613, 9.614639282226562, 10.825362205505371)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
            " 40%|████      | 2/5 [00:00<00:00,  4.34it/s]\u001b[A\n",
            " 60%|██████    | 3/5 [00:00<00:00,  3.41it/s]\u001b[A\n",
            " 80%|████████  | 4/5 [00:01<00:00,  2.97it/s]\u001b[A\n",
            "100%|██████████| 5/5 [00:01<00:00,  3.04it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num dead tensor(0.4941, device='cuda:0')\n",
            "Saved as version 47\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
            "  4%|▍         | 2/50 [00:00<00:10,  4.60it/s]\u001b[A\n",
            "  6%|▌         | 3/50 [00:00<00:13,  3.45it/s]\u001b[A\n",
            "  8%|▊         | 4/50 [00:01<00:15,  3.02it/s]\u001b[A\n",
            " 10%|█         | 5/50 [00:01<00:15,  2.83it/s]\u001b[A\n",
            " 12%|█▏        | 6/50 [00:02<00:16,  2.73it/s]\u001b[A\n",
            " 14%|█▍        | 7/50 [00:02<00:16,  2.66it/s]\u001b[A\n",
            " 16%|█▌        | 8/50 [00:02<00:16,  2.62it/s]\u001b[A\n",
            " 18%|█▊        | 9/50 [00:03<00:15,  2.58it/s]\u001b[A\n",
            " 20%|██        | 10/50 [00:03<00:15,  2.57it/s]\u001b[A\n",
            " 22%|██▏       | 11/50 [00:03<00:15,  2.55it/s]\u001b[A\n",
            " 24%|██▍       | 12/50 [00:04<00:14,  2.54it/s]\u001b[A\n",
            " 26%|██▌       | 13/50 [00:04<00:14,  2.54it/s]\u001b[A\n",
            " 28%|██▊       | 14/50 [00:05<00:14,  2.54it/s]\u001b[A\n",
            " 30%|███       | 15/50 [00:05<00:13,  2.54it/s]\u001b[A\n",
            " 32%|███▏      | 16/50 [00:05<00:13,  2.52it/s]\u001b[A\n",
            " 34%|███▍      | 17/50 [00:06<00:13,  2.52it/s]\u001b[A\n",
            " 36%|███▌      | 18/50 [00:06<00:12,  2.52it/s]\u001b[A\n",
            " 38%|███▊      | 19/50 [00:07<00:12,  2.53it/s]\u001b[A\n",
            " 40%|████      | 20/50 [00:07<00:11,  2.52it/s]\u001b[A\n",
            " 42%|████▏     | 21/50 [00:07<00:11,  2.53it/s]\u001b[A\n",
            " 44%|████▍     | 22/50 [00:08<00:11,  2.52it/s]\u001b[A\n",
            " 46%|████▌     | 23/50 [00:08<00:10,  2.53it/s]\u001b[A\n",
            " 48%|████▊     | 24/50 [00:09<00:10,  2.52it/s]\u001b[A\n",
            " 50%|█████     | 25/50 [00:09<00:09,  2.53it/s]\u001b[A\n",
            " 52%|█████▏    | 26/50 [00:09<00:09,  2.51it/s]\u001b[A\n",
            " 54%|█████▍    | 27/50 [00:10<00:09,  2.51it/s]\u001b[A\n",
            " 56%|█████▌    | 28/50 [00:10<00:08,  2.53it/s]\u001b[A\n",
            " 58%|█████▊    | 29/50 [00:11<00:08,  2.52it/s]\u001b[A\n",
            " 60%|██████    | 30/50 [00:11<00:07,  2.53it/s]\u001b[A\n",
            " 62%|██████▏   | 31/50 [00:11<00:07,  2.52it/s]\u001b[A\n",
            " 64%|██████▍   | 32/50 [00:12<00:07,  2.51it/s]\u001b[A\n",
            " 66%|██████▌   | 33/50 [00:12<00:06,  2.52it/s]\u001b[A\n",
            " 68%|██████▊   | 34/50 [00:13<00:06,  2.53it/s]\u001b[A\n",
            " 70%|███████   | 35/50 [00:13<00:05,  2.53it/s]\u001b[A\n",
            " 72%|███████▏  | 36/50 [00:13<00:05,  2.53it/s]\u001b[A\n",
            " 74%|███████▍  | 37/50 [00:14<00:05,  2.53it/s]\u001b[A\n",
            " 76%|███████▌  | 38/50 [00:14<00:04,  2.53it/s]\u001b[A\n",
            " 78%|███████▊  | 39/50 [00:15<00:04,  2.52it/s]\u001b[A\n",
            " 80%|████████  | 40/50 [00:15<00:03,  2.51it/s]\u001b[A\n",
            " 82%|████████▏ | 41/50 [00:15<00:03,  2.52it/s]\u001b[A\n",
            " 84%|████████▍ | 42/50 [00:16<00:03,  2.52it/s]\u001b[A\n",
            " 86%|████████▌ | 43/50 [00:16<00:02,  2.53it/s]\u001b[A\n",
            " 88%|████████▊ | 44/50 [00:17<00:02,  2.52it/s]\u001b[A\n",
            " 90%|█████████ | 45/50 [00:17<00:01,  2.52it/s]\u001b[A\n",
            " 92%|█████████▏| 46/50 [00:17<00:01,  2.52it/s]\u001b[A\n",
            " 94%|█████████▍| 47/50 [00:18<00:01,  2.51it/s]\u001b[A\n",
            " 96%|█████████▌| 48/50 [00:18<00:00,  2.53it/s]\u001b[A\n",
            " 98%|█████████▊| 49/50 [00:19<00:00,  2.53it/s]\u001b[A\n",
            "100%|██████████| 50/50 [00:19<00:00,  2.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num dead "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|████████  | 1000/1250 [13:30<41:52, 10.05s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.1348, device='cuda:0')\n",
            "Resetting neurons! tensor(207, device='cuda:0')\n",
            "torch.Size([1536, 768]) torch.Size([768, 1536]) torch.Size([1536])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 88%|████████▊ | 1100/1250 [14:45<01:52,  1.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'loss': 157.2391357421875, 'l2_loss': 32.00498962402344, 'l1_loss': 125.23414611816406}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 96%|█████████▌| 1200/1250 [15:59<00:37,  1.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'loss': 156.4464111328125, 'l2_loss': 31.889694213867188, 'l1_loss': 124.55672454833984}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1250/1250 [16:37<00:00,  1.25it/s]\n",
            "  8%|▊         | 100/1250 [01:14<14:11,  1.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'loss': 157.82537841796875, 'l2_loss': 32.42594528198242, 'l1_loss': 125.3994369506836}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 16%|█▌        | 200/1250 [02:28<12:59,  1.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'loss': 158.70159912109375, 'l2_loss': 34.894020080566406, 'l1_loss': 123.80758666992188}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 24%|██▍       | 300/1250 [03:42<11:44,  1.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'loss': 155.95082092285156, 'l2_loss': 36.01087188720703, 'l1_loss': 119.93994903564453}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 32%|███▏      | 400/1250 [04:56<10:28,  1.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'loss': 157.43365478515625, 'l2_loss': 32.501319885253906, 'l1_loss': 124.93234252929688}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 40%|███▉      | 499/1250 [06:10<09:21,  1.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'loss': 154.39874267578125, 'l2_loss': 30.551908493041992, 'l1_loss': 123.84683227539062}\n",
            "9.519570350646973 9.540260314941406 10.825362205505371\n",
            "98.42%\n",
            "Reconstruction: (0.9841552356009471, 9.519570350646973, 9.540260314941406, 10.825362205505371)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
            " 40%|████      | 2/5 [00:00<00:00,  4.39it/s]\u001b[A\n",
            " 60%|██████    | 3/5 [00:00<00:00,  3.45it/s]\u001b[A\n",
            " 80%|████████  | 4/5 [00:01<00:00,  2.99it/s]\u001b[A\n",
            "100%|██████████| 5/5 [00:01<00:00,  3.04it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num dead tensor(0.4141, device='cuda:0')\n",
            "Saved as version 48\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
            "  4%|▍         | 2/50 [00:00<00:10,  4.68it/s]\u001b[A\n",
            "  6%|▌         | 3/50 [00:00<00:13,  3.46it/s]\u001b[A\n",
            "  8%|▊         | 4/50 [00:01<00:15,  3.01it/s]\u001b[A\n",
            " 10%|█         | 5/50 [00:01<00:15,  2.84it/s]\u001b[A\n",
            " 12%|█▏        | 6/50 [00:02<00:16,  2.73it/s]\u001b[A\n",
            " 14%|█▍        | 7/50 [00:02<00:16,  2.66it/s]\u001b[A\n",
            " 16%|█▌        | 8/50 [00:02<00:15,  2.63it/s]\u001b[A\n",
            " 18%|█▊        | 9/50 [00:03<00:15,  2.58it/s]\u001b[A\n",
            " 20%|██        | 10/50 [00:03<00:15,  2.57it/s]\u001b[A\n",
            " 22%|██▏       | 11/50 [00:03<00:15,  2.56it/s]\u001b[A\n",
            " 24%|██▍       | 12/50 [00:04<00:15,  2.53it/s]\u001b[A\n",
            " 26%|██▌       | 13/50 [00:04<00:14,  2.54it/s]\u001b[A\n",
            " 28%|██▊       | 14/50 [00:05<00:14,  2.54it/s]\u001b[A\n",
            " 30%|███       | 15/50 [00:05<00:13,  2.52it/s]\u001b[A\n",
            " 32%|███▏      | 16/50 [00:05<00:13,  2.52it/s]\u001b[A\n",
            " 34%|███▍      | 17/50 [00:06<00:13,  2.52it/s]\u001b[A\n",
            " 36%|███▌      | 18/50 [00:06<00:12,  2.53it/s]\u001b[A\n",
            " 38%|███▊      | 19/50 [00:07<00:12,  2.53it/s]\u001b[A\n",
            " 40%|████      | 20/50 [00:07<00:11,  2.53it/s]\u001b[A\n",
            " 42%|████▏     | 21/50 [00:07<00:11,  2.52it/s]\u001b[A\n",
            " 44%|████▍     | 22/50 [00:08<00:11,  2.53it/s]\u001b[A\n",
            " 46%|████▌     | 23/50 [00:08<00:10,  2.52it/s]\u001b[A\n",
            " 48%|████▊     | 24/50 [00:09<00:10,  2.53it/s]\u001b[A\n",
            " 50%|█████     | 25/50 [00:09<00:09,  2.51it/s]\u001b[A\n",
            " 52%|█████▏    | 26/50 [00:09<00:09,  2.53it/s]\u001b[A\n",
            " 54%|█████▍    | 27/50 [00:10<00:09,  2.52it/s]\u001b[A\n",
            " 56%|█████▌    | 28/50 [00:10<00:08,  2.53it/s]\u001b[A\n",
            " 58%|█████▊    | 29/50 [00:11<00:08,  2.53it/s]\u001b[A\n",
            " 60%|██████    | 30/50 [00:11<00:07,  2.53it/s]\u001b[A\n",
            " 62%|██████▏   | 31/50 [00:11<00:07,  2.53it/s]\u001b[A\n",
            " 64%|██████▍   | 32/50 [00:12<00:07,  2.52it/s]\u001b[A\n",
            " 66%|██████▌   | 33/50 [00:12<00:06,  2.53it/s]\u001b[A\n",
            " 68%|██████▊   | 34/50 [00:13<00:06,  2.52it/s]\u001b[A\n",
            " 70%|███████   | 35/50 [00:13<00:05,  2.53it/s]\u001b[A\n",
            " 72%|███████▏  | 36/50 [00:13<00:05,  2.51it/s]\u001b[A\n",
            " 74%|███████▍  | 37/50 [00:14<00:05,  2.53it/s]\u001b[A\n",
            " 76%|███████▌  | 38/50 [00:14<00:04,  2.51it/s]\u001b[A\n",
            " 78%|███████▊  | 39/50 [00:15<00:04,  2.52it/s]\u001b[A\n",
            " 80%|████████  | 40/50 [00:15<00:03,  2.52it/s]\u001b[A\n",
            " 82%|████████▏ | 41/50 [00:15<00:03,  2.51it/s]\u001b[A\n",
            " 84%|████████▍ | 42/50 [00:16<00:03,  2.53it/s]\u001b[A\n",
            " 86%|████████▌ | 43/50 [00:16<00:02,  2.52it/s]\u001b[A\n",
            " 88%|████████▊ | 44/50 [00:17<00:02,  2.52it/s]\u001b[A\n",
            " 90%|█████████ | 45/50 [00:17<00:01,  2.53it/s]\u001b[A\n",
            " 92%|█████████▏| 46/50 [00:17<00:01,  2.52it/s]\u001b[A\n",
            " 94%|█████████▍| 47/50 [00:18<00:01,  2.53it/s]\u001b[A\n",
            " 96%|█████████▌| 48/50 [00:18<00:00,  2.53it/s]\u001b[A\n",
            " 98%|█████████▊| 49/50 [00:19<00:00,  2.52it/s]\u001b[A\n",
            "100%|██████████| 50/50 [00:19<00:00,  2.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num dead "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|████      | 500/1250 [06:41<2:05:39, 10.05s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0905, device='cuda:0')\n",
            "Resetting neurons! tensor(139, device='cuda:0')\n",
            "torch.Size([1536, 768]) torch.Size([768, 1536]) torch.Size([1536])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 48%|████▊     | 600/1250 [07:56<08:05,  1.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'loss': 154.52767944335938, 'l2_loss': 30.578054428100586, 'l1_loss': 123.94963073730469}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 56%|█████▌    | 700/1250 [09:10<06:50,  1.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'loss': 151.96009826660156, 'l2_loss': 29.811382293701172, 'l1_loss': 122.14871978759766}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 64%|██████▍   | 800/1250 [10:25<05:35,  1.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'loss': 153.05035400390625, 'l2_loss': 31.76234245300293, 'l1_loss': 121.28801727294922}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 72%|███████▏  | 900/1250 [11:39<04:19,  1.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'loss': 152.17774963378906, 'l2_loss': 32.47003173828125, 'l1_loss': 119.70771789550781}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 80%|███████▉  | 999/1250 [12:53<03:06,  1.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'loss': 155.60337829589844, 'l2_loss': 32.079833984375, 'l1_loss': 123.52354431152344}\n",
            "9.653242111206055 9.577951431274414 10.825362205505371\n",
            "106.42%\n",
            "Reconstruction: (1.064234612389824, 9.653242111206055, 9.577951431274414, 10.825362205505371)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
            " 40%|████      | 2/5 [00:00<00:00,  4.44it/s]\u001b[A\n",
            " 60%|██████    | 3/5 [00:00<00:00,  3.47it/s]\u001b[A\n",
            " 80%|████████  | 4/5 [00:01<00:00,  3.00it/s]\u001b[A\n",
            "100%|██████████| 5/5 [00:01<00:00,  3.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num dead tensor(0.0846, device='cuda:0')\n",
            "Saved as version 49\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
            "  4%|▍         | 2/50 [00:00<00:10,  4.68it/s]\u001b[A\n",
            "  6%|▌         | 3/50 [00:00<00:13,  3.48it/s]\u001b[A\n",
            "  8%|▊         | 4/50 [00:01<00:15,  3.04it/s]\u001b[A\n",
            " 10%|█         | 5/50 [00:01<00:15,  2.85it/s]\u001b[A\n",
            " 12%|█▏        | 6/50 [00:02<00:16,  2.72it/s]\u001b[A\n",
            " 14%|█▍        | 7/50 [00:02<00:16,  2.67it/s]\u001b[A\n",
            " 16%|█▌        | 8/50 [00:02<00:15,  2.63it/s]\u001b[A\n",
            " 18%|█▊        | 9/50 [00:03<00:15,  2.58it/s]\u001b[A\n",
            " 20%|██        | 10/50 [00:03<00:15,  2.57it/s]\u001b[A\n",
            " 22%|██▏       | 11/50 [00:03<00:15,  2.56it/s]\u001b[A\n",
            " 24%|██▍       | 12/50 [00:04<00:14,  2.55it/s]\u001b[A\n",
            " 26%|██▌       | 13/50 [00:04<00:14,  2.54it/s]\u001b[A\n",
            " 28%|██▊       | 14/50 [00:05<00:14,  2.53it/s]\u001b[A\n",
            " 30%|███       | 15/50 [00:05<00:13,  2.54it/s]\u001b[A\n",
            " 32%|███▏      | 16/50 [00:05<00:13,  2.53it/s]\u001b[A\n",
            " 34%|███▍      | 17/50 [00:06<00:12,  2.54it/s]\u001b[A\n",
            " 36%|███▌      | 18/50 [00:06<00:12,  2.54it/s]\u001b[A\n",
            " 38%|███▊      | 19/50 [00:07<00:12,  2.52it/s]\u001b[A\n",
            " 40%|████      | 20/50 [00:07<00:11,  2.53it/s]\u001b[A\n",
            " 42%|████▏     | 21/50 [00:07<00:11,  2.54it/s]\u001b[A\n",
            " 44%|████▍     | 22/50 [00:08<00:11,  2.53it/s]\u001b[A\n",
            " 46%|████▌     | 23/50 [00:08<00:10,  2.53it/s]\u001b[A\n",
            " 48%|████▊     | 24/50 [00:09<00:10,  2.52it/s]\u001b[A\n",
            " 50%|█████     | 25/50 [00:09<00:09,  2.51it/s]\u001b[A\n",
            " 52%|█████▏    | 26/50 [00:09<00:09,  2.53it/s]\u001b[A\n",
            " 54%|█████▍    | 27/50 [00:10<00:09,  2.52it/s]\u001b[A\n",
            " 56%|█████▌    | 28/50 [00:10<00:08,  2.52it/s]\u001b[A\n",
            " 58%|█████▊    | 29/50 [00:11<00:08,  2.52it/s]\u001b[A\n",
            " 60%|██████    | 30/50 [00:11<00:07,  2.52it/s]\u001b[A\n",
            " 62%|██████▏   | 31/50 [00:11<00:07,  2.53it/s]\u001b[A\n",
            " 64%|██████▍   | 32/50 [00:12<00:07,  2.53it/s]\u001b[A\n",
            " 66%|██████▌   | 33/50 [00:12<00:06,  2.52it/s]\u001b[A\n",
            " 68%|██████▊   | 34/50 [00:13<00:06,  2.52it/s]\u001b[A\n",
            " 70%|███████   | 35/50 [00:13<00:05,  2.53it/s]\u001b[A\n",
            " 72%|███████▏  | 36/50 [00:13<00:05,  2.52it/s]\u001b[A\n",
            " 74%|███████▍  | 37/50 [00:14<00:05,  2.53it/s]\u001b[A\n",
            " 76%|███████▌  | 38/50 [00:14<00:04,  2.52it/s]\u001b[A\n",
            " 78%|███████▊  | 39/50 [00:15<00:04,  2.51it/s]\u001b[A\n",
            " 80%|████████  | 40/50 [00:15<00:03,  2.52it/s]\u001b[A\n",
            " 82%|████████▏ | 41/50 [00:15<00:03,  2.53it/s]\u001b[A\n",
            " 84%|████████▍ | 42/50 [00:16<00:03,  2.53it/s]\u001b[A\n",
            " 86%|████████▌ | 43/50 [00:16<00:02,  2.53it/s]\u001b[A\n",
            " 88%|████████▊ | 44/50 [00:17<00:02,  2.51it/s]\u001b[A\n",
            " 90%|█████████ | 45/50 [00:17<00:01,  2.53it/s]\u001b[A\n",
            " 92%|█████████▏| 46/50 [00:17<00:01,  2.52it/s]\u001b[A\n",
            " 94%|█████████▍| 47/50 [00:18<00:01,  2.52it/s]\u001b[A\n",
            " 96%|█████████▌| 48/50 [00:18<00:00,  2.53it/s]\u001b[A\n",
            " 98%|█████████▊| 49/50 [00:19<00:00,  2.53it/s]\u001b[A\n",
            "100%|██████████| 50/50 [00:19<00:00,  2.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num dead "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|████████  | 1000/1250 [13:25<41:52, 10.05s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0918, device='cuda:0')\n",
            "Resetting neurons! tensor(141, device='cuda:0')\n",
            "torch.Size([1536, 768]) torch.Size([768, 1536]) torch.Size([1536])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 88%|████████▊ | 1100/1250 [14:39<01:51,  1.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'loss': 151.1935577392578, 'l2_loss': 29.00714111328125, 'l1_loss': 122.18641662597656}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 96%|█████████▌| 1200/1250 [15:54<00:37,  1.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'loss': 153.392333984375, 'l2_loss': 30.90787124633789, 'l1_loss': 122.48445892333984}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1250/1250 [16:31<00:00,  1.26it/s]\n",
            "  8%|▊         | 100/1250 [01:14<14:12,  1.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'loss': 155.57455444335938, 'l2_loss': 30.14177703857422, 'l1_loss': 125.43277740478516}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 12%|█▏        | 153/1250 [01:53<13:33,  1.35it/s]"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "58d4136a18504291bb6162b29a8d088e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_de0dbc1b23264c0e954db73a809b7b1a",
              "IPY_MODEL_34a0e383f57c49e394abcec2a51e60a8"
            ],
            "layout": "IPY_MODEL_75ec369fa7af48b4bee348227f5a8a2c"
          }
        },
        "de0dbc1b23264c0e954db73a809b7b1a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0ba7c4538cbe49b28cb0909004654a15",
            "placeholder": "​",
            "style": "IPY_MODEL_296cb82af3d54cdb99e519f853a540c1",
            "value": "0.013 MB of 0.013 MB uploaded\r"
          }
        },
        "34a0e383f57c49e394abcec2a51e60a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9b57174460ae48b6b89c8f0ec8203958",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fe4e854d65a248c4a3ce1ad88c509be3",
            "value": 1
          }
        },
        "75ec369fa7af48b4bee348227f5a8a2c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0ba7c4538cbe49b28cb0909004654a15": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "296cb82af3d54cdb99e519f853a540c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9b57174460ae48b6b89c8f0ec8203958": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fe4e854d65a248c4a3ce1ad88c509be3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}